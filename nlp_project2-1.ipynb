{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PP8vKkgymNq",
        "outputId": "3d99a940-6923-48d1-9035-8ae22f1cfa78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/muhammadahmedansari/urdu-dataset-20000?dataset_version_number=4...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3.95G/3.95G [00:46<00:00, 91.7MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/muhammadahmedansari/urdu-dataset-20000/versions/4\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"muhammadahmedansari/urdu-dataset-20000\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh_KpuiVz1im",
        "outputId": "6174c31b-efb9-446b-ee18-2b028be34dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files in dataset directory:\n",
            "  - char_to_num_vocab.pkl\n",
            "  - model_checkpoint_v2.h5\n",
            "  - limited_wav_files\n",
            "  - final_main_dataset.tsv\n",
            "\n",
            "Found 1 TSV file(s): ['final_main_dataset.tsv']\n",
            "\n",
            "======================================================================\n",
            "DATASET OVERVIEW\n",
            "======================================================================\n",
            "Shape: 20000 rows × 11 columns\n",
            "\n",
            "Column names:\n",
            "  0: client_id\n",
            "  1: path\n",
            "  2: sentence\n",
            "  3: up_votes\n",
            "  4: down_votes\n",
            "  5: age\n",
            "  6: gender\n",
            "  7: accents\n",
            "  8: variant\n",
            "  9: locale\n",
            "  10: segment\n",
            "\n",
            "======================================================================\n",
            "FIRST 5 ROWS\n",
            "======================================================================\n",
            "                                           client_id  \\\n",
            "0  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "1  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "2  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "3  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "4  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "\n",
            "                           path  \\\n",
            "0  common_voice_ur_31771683.mp3   \n",
            "1  common_voice_ur_31771684.mp3   \n",
            "2  common_voice_ur_31771685.mp3   \n",
            "3  common_voice_ur_31771730.mp3   \n",
            "4  common_voice_ur_31771732.mp3   \n",
            "\n",
            "                                            sentence  up_votes  down_votes  \\\n",
            "0                 کبھی کبھار ہی خیالی پلاو بناتا ہوں         2           0   \n",
            "1                  اور پھر ممکن ہے کہ پاکستان بھی ہو         2           1   \n",
            "2                      یہ فیصلہ بھی گزشتہ دو سال میں         2           0   \n",
            "3                     ان کے بلے بازوں کے سامنے ہو گا         3           0   \n",
            "4  آبی جانور میں بطخ بگلا اور دُوسْرا آبی پرندہ ش...         3           0   \n",
            "\n",
            "        age gender accents  variant locale  segment  \n",
            "0  twenties   male     NaN      NaN     ur      NaN  \n",
            "1  twenties   male     NaN      NaN     ur      NaN  \n",
            "2  twenties   male     NaN      NaN     ur      NaN  \n",
            "3  twenties   male     NaN      NaN     ur      NaN  \n",
            "4  twenties   male     NaN      NaN     ur      NaN  \n",
            "\n",
            "======================================================================\n",
            "DATA TYPES\n",
            "======================================================================\n",
            "client_id      object\n",
            "path           object\n",
            "sentence       object\n",
            "up_votes        int64\n",
            "down_votes      int64\n",
            "age            object\n",
            "gender         object\n",
            "accents        object\n",
            "variant       float64\n",
            "locale         object\n",
            "segment       float64\n",
            "dtype: object\n",
            "\n",
            "======================================================================\n",
            "MISSING VALUES\n",
            "======================================================================\n",
            "client_id         0\n",
            "path              0\n",
            "sentence          0\n",
            "up_votes          0\n",
            "down_votes        0\n",
            "age            3802\n",
            "gender         3802\n",
            "accents       17467\n",
            "variant       20000\n",
            "locale            0\n",
            "segment       20000\n",
            "dtype: int64\n",
            "\n",
            "======================================================================\n",
            "SAMPLE DATA (Random 3 rows)\n",
            "======================================================================\n",
            "                                               client_id  \\\n",
            "7719   e02a6bd3a9b91f05a4a20ed526628fd6a3ec4ba2175075...   \n",
            "15330  3606b5a1ca688436612810d65531bd6166225193c405c9...   \n",
            "15998  29ead781ab18e6328ebacedd88885bfdd2935f0b8598ef...   \n",
            "\n",
            "                               path  \\\n",
            "7719   common_voice_ur_26995490.mp3   \n",
            "15330  common_voice_ur_31978754.mp3   \n",
            "15998  common_voice_ur_31825554.mp3   \n",
            "\n",
            "                                                sentence  up_votes  \\\n",
            "7719      پنجاب بھر میں چینی کا بحران سنگین ہونے کا خدشہ         2   \n",
            "15330                               تو چلیےشروع کرتے ہیں         5   \n",
            "15998  میں لیوائز کے ساتھ اپنی میوزک ویڈیو کی ریلیز پ...         2   \n",
            "\n",
            "       down_votes       age gender accents  variant locale  segment  \n",
            "7719            0  twenties   male     NaN      NaN     ur      NaN  \n",
            "15330           0  twenties   male     NaN      NaN     ur      NaN  \n",
            "15998           0  twenties   male     NaN      NaN     ur      NaN  \n",
            "\n",
            "======================================================================\n",
            "BASIC STATISTICS\n",
            "======================================================================\n",
            "\n",
            "Text column: 'client_id'\n",
            "Sample text: e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca60e58fb87ea68a35d53dcae445c65d5e73e0449a0b1cf2b4d09f32874877e8786664aa50f1f2ec2b932\n",
            "\n",
            "Text lengths (characters):\n",
            "  Min: 128\n",
            "  Max: 128\n",
            "  Mean: 128.00\n",
            "  Median: 128.00\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CELL 2: Explore Dataset Structure\n",
        "# ============================================================================\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# List all files in the downloaded path\n",
        "print(\"Files in dataset directory:\")\n",
        "for file in os.listdir(path):\n",
        "    print(f\"  - {file}\")\n",
        "\n",
        "# Find and load TSV files\n",
        "tsv_files = [f for f in os.listdir(path) if f.endswith('.tsv')]\n",
        "print(f\"\\nFound {len(tsv_files)} TSV file(s): {tsv_files}\")\n",
        "\n",
        "# Load the first TSV file\n",
        "if tsv_files:\n",
        "    df = pd.read_csv(os.path.join(path, tsv_files[0]), sep='\\t')\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"DATASET OVERVIEW\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
        "    print(f\"\\nColumn names:\")\n",
        "    for i, col in enumerate(df.columns):\n",
        "        print(f\"  {i}: {col}\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"FIRST 5 ROWS\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(df.head())\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"DATA TYPES\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(df.dtypes)\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"MISSING VALUES\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"SAMPLE DATA (Random 3 rows)\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(df.sample(3))\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"BASIC STATISTICS\")\n",
        "    print(f\"{'='*70}\")\n",
        "    if df.select_dtypes(include=['object']).shape[1] > 0:\n",
        "        text_col = df.select_dtypes(include=['object']).columns[0]\n",
        "        print(f\"\\nText column: '{text_col}'\")\n",
        "        print(f\"Sample text: {df[text_col].iloc[0]}\")\n",
        "        print(f\"\\nText lengths (characters):\")\n",
        "        text_lengths = df[text_col].astype(str).str.len()\n",
        "        print(f\"  Min: {text_lengths.min()}\")\n",
        "        print(f\"  Max: {text_lengths.max()}\")\n",
        "        print(f\"  Mean: {text_lengths.mean():.2f}\")\n",
        "        print(f\"  Median: {text_lengths.median():.2f}\")\n",
        "else:\n",
        "    print(\"No TSV files found!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJLu-n76z7vV",
        "outputId": "5b47a3b2-ac2d-4d00-ddee-4d97b7a11ab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 3: Import Required Libraries\n",
        "# ============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UszdGYooz_bq",
        "outputId": "6de3d4f8-ed9d-4c5f-dbd5-9287aa1ccd68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing preprocessing functions:\n",
            "Original: یہ ایک ٹیسٹ جملہ ہے۔\n",
            "Normalized: یہ ایک ٹیسٹ جملہ ہی۔\n",
            "Tokens: ['یہ', 'ایک', 'ٹیسٹ', 'جملہ', 'ہی۔']\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 4: Urdu Text Preprocessing Functions\n",
        "# ============================================================================\n",
        "import unicodedata\n",
        "\n",
        "def normalize_urdu_text(text):\n",
        "    \"\"\"Normalize Urdu text: remove diacritics, standardize Alef and Yeh\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Remove diacritics\n",
        "    text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')\n",
        "\n",
        "    # Standardize Alef forms\n",
        "    alef_forms = ['آ', 'أ', 'إ', 'ا']\n",
        "    for alef in alef_forms:\n",
        "        text = text.replace(alef, 'ا')\n",
        "\n",
        "    # Standardize Yeh forms\n",
        "    yeh_forms = ['ی', 'ي', 'ے']\n",
        "    for yeh in yeh_forms:\n",
        "        text = text.replace(yeh, 'ی')\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "def tokenize_urdu(text):\n",
        "    \"\"\"Simple word-level tokenization for Urdu\"\"\"\n",
        "    text = normalize_urdu_text(text)\n",
        "    tokens = re.findall(r'\\S+', text)\n",
        "    return tokens\n",
        "\n",
        "# Test the functions\n",
        "print(\"Testing preprocessing functions:\")\n",
        "test_text = \"یہ ایک ٹیسٹ جملہ ہے۔\"\n",
        "print(f\"Original: {test_text}\")\n",
        "print(f\"Normalized: {normalize_urdu_text(test_text)}\")\n",
        "print(f\"Tokens: {tokenize_urdu(test_text)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3eRTOfM0ChR",
        "outputId": "e0045bf1-b8cc-4302-b326-ff7e648c90e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CREATING BALANCED CONVERSATIONAL DATASET\n",
            "======================================================================\n",
            "======================================================================\n",
            "MULTI-STRATEGY PAIR CREATION\n",
            "Target: 10000 pairs\n",
            "======================================================================\n",
            "\n",
            "[1/5] Question-Answer pairs...\n",
            "  ✓ Found 1837 question-answer pairs\n",
            "\n",
            "[2/5] High-overlap adjacent pairs...\n",
            "  ✓ Found 398 high-overlap pairs\n",
            "\n",
            "[3/5] Context-response pairs...\n",
            "  ✓ Found 1740 context-response pairs\n",
            "\n",
            "[4/5] Topic continuation pairs...\n",
            "  ✓ Found 18715 continuation pairs\n",
            "\n",
            "[5/5] Sentence splitting for augmentation...\n",
            "  ✓ Created 3 split pairs\n",
            "\n",
            "======================================================================\n",
            "DEDUPLICATION\n",
            "======================================================================\n",
            "Before deduplication: 22693 pairs\n",
            "After deduplication:  17017 pairs\n",
            "\n",
            "======================================================================\n",
            "FINAL DATASET SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Total pairs: 17017\n",
            "\n",
            "Breakdown by type:\n",
            "type\n",
            "continuation        13701\n",
            "question-answer      1530\n",
            "context-response     1495\n",
            "high-overlap          288\n",
            "split                   3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Breakdown by quality:\n",
            "quality\n",
            "medium    15199\n",
            "high       1818\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Relatedness statistics:\n",
            "  Min:    0.0000\n",
            "  Max:    0.7000\n",
            "  Mean:   0.0123\n",
            "  Median: 0.0000\n",
            "\n",
            "======================================================================\n",
            "SAMPLES FROM EACH TYPE\n",
            "======================================================================\n",
            "\n",
            "--- QUESTION-ANSWER ---\n",
            "Input:    ہم اور کیا چاہتے ہیں۔...\n",
            "Response: ہم سے جہاں میں کشتۂ غم اور کیا نہ تھے...\n",
            "Relatedness: 0.222\n",
            "\n",
            "Input:    تو اس کا حل کیا ہے؟...\n",
            "Response: مثالیں کیا دیں۔...\n",
            "Relatedness: 0.200\n",
            "\n",
            "\n",
            "--- HIGH-OVERLAP ---\n",
            "Input:    وہی غفورالرحیم ہے کہ ہماری خطائیں بخش دے وہی سلام ہے کہ سلامتی عطافرمائے...\n",
            "Response: وہی غفورالرحیم ہے کہ ہماری خطائیں بخش دے...\n",
            "Relatedness: 0.700\n",
            "\n",
            "Input:    یہ جو موجودہ ہیں۔...\n",
            "Response: جو سوکھے لوگ ہیں۔...\n",
            "Relatedness: 0.400\n",
            "\n",
            "\n",
            "--- CONTEXT-RESPONSE ---\n",
            "Input:    خلیفہ کے حکم کے بغیر نہ وعظ کہتے تھے اور نہ فتویٰ دیتے تھے وہی غفورالرحیم ہے کہ ...\n",
            "Response: وہی غفورالرحیم ہے کہ ہماری خطائیں بخش دے...\n",
            "Relatedness: 0.368\n",
            "\n",
            "Input:    یہ نہیں کہا جائے گا کہ فلاں شخص کافر ہے پھر پاکستان کے قبضے میں آنے والی...\n",
            "Response: کہ کوئی حکم نہیں لگایا جائے گا...\n",
            "Relatedness: 0.250\n",
            "\n",
            "\n",
            "--- CONTINUATION ---\n",
            "Input:    جتنے کے تھے۔...\n",
            "Response: یہ چینی تھے۔...\n",
            "Relatedness: 0.333\n",
            "\n",
            "Input:    ایسا کرنا ہے۔...\n",
            "Response: تو اس سے زیادہ سے زیادہ نفع حاصل کرنا چاہتا ہے۔...\n",
            "Relatedness: 0.286\n",
            "\n",
            "\n",
            "--- SPLIT ---\n",
            "Input:    ان مسائل کے تناظر میں بنگلہ دیش کی عدالتِ عالیہ کا فیصلہ ہمارے نزدیک...\n",
            "Response: امت کی تاریخ میں ایک عظیم فیصلہ ہے...\n",
            "Relatedness: 0.077\n",
            "\n",
            "Input:    کاربن ڈائی آکسائیڈ گیس اور آبی بخارات کے علاوہ...\n",
            "Response: دوسری گیسیں بھی فضا میں شامل ہوکر گرمی میں اضافے کا سبب بن سکتی ہیں...\n",
            "Relatedness: 0.000\n",
            "\n",
            "\n",
            "======================================================================\n",
            "✓ Dataset ready with 17017 conversational pairs!\n",
            "======================================================================\n",
            "\n",
            "✓ Good: 17017 pairs is sufficient for training!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 5: BALANCED - Conversational Pairs (Quantity + Quality)\n",
        "# ============================================================================\n",
        "\n",
        "def has_question_marker(text):\n",
        "    \"\"\"Check for question mark\"\"\"\n",
        "    return '؟' in text\n",
        "\n",
        "def has_question_words(text):\n",
        "    \"\"\"Check for Urdu question words\"\"\"\n",
        "    question_words = ['کیا', 'کیوں', 'کب', 'کہاں', 'کون', 'کیسے', 'کتنا', 'کتنی', 'کس', 'کونسا']\n",
        "    tokens = tokenize_urdu(text)\n",
        "    return any(word in tokens for word in question_words)\n",
        "\n",
        "def is_question(text):\n",
        "    \"\"\"Question detection\"\"\"\n",
        "    return has_question_marker(text) or has_question_words(text)\n",
        "\n",
        "def calculate_semantic_relatedness(text1, text2):\n",
        "    \"\"\"Calculate word overlap between texts\"\"\"\n",
        "    words1 = set(tokenize_urdu(text1))\n",
        "    words2 = set(tokenize_urdu(text2))\n",
        "\n",
        "    # Remove common stop words\n",
        "    stop_words = {'کی', 'میں', 'ہی', 'کا', 'سی', 'کو', 'اور', 'اس', 'یہ', 'نی', 'پر', 'تو', 'بھی', 'ہیں', 'ایک', 'وہ'}\n",
        "    words1 = words1 - stop_words\n",
        "    words2 = words2 - stop_words\n",
        "\n",
        "    if len(words1) == 0 or len(words2) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    intersection = len(words1 & words2)\n",
        "    union = len(words1 | words2)\n",
        "\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "def create_balanced_pairs(df, target_pairs=10000):\n",
        "    \"\"\"\n",
        "    Create conversational pairs with BALANCED quality vs quantity\n",
        "    Target: Get at least 10,000 pairs\n",
        "    \"\"\"\n",
        "    all_pairs = []\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"MULTI-STRATEGY PAIR CREATION\")\n",
        "    print(f\"Target: {target_pairs} pairs\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ========================================================================\n",
        "    # STRATEGY 1: Question-Answer (HIGHEST QUALITY)\n",
        "    # ========================================================================\n",
        "    print(\"\\n[1/5] Question-Answer pairs...\")\n",
        "    qa_pairs = []\n",
        "\n",
        "    for i in range(len(df) - 1):\n",
        "        input_text = str(df.iloc[i]['sentence']).strip()\n",
        "        response_text = str(df.iloc[i+1]['sentence']).strip()\n",
        "\n",
        "        if is_question(input_text):\n",
        "            if (10 < len(input_text) < 150 and 10 < len(response_text) < 150):\n",
        "                relatedness = calculate_semantic_relatedness(input_text, response_text)\n",
        "                qa_pairs.append({\n",
        "                    'input': input_text,\n",
        "                    'response': response_text,\n",
        "                    'type': 'question-answer',\n",
        "                    'quality': 'high',\n",
        "                    'relatedness': relatedness\n",
        "                })\n",
        "\n",
        "    print(f\"  ✓ Found {len(qa_pairs)} question-answer pairs\")\n",
        "    all_pairs.extend(qa_pairs)\n",
        "\n",
        "    # ========================================================================\n",
        "    # STRATEGY 2: High-Overlap Adjacent Sentences (HIGH QUALITY)\n",
        "    # ========================================================================\n",
        "    print(\"\\n[2/5] High-overlap adjacent pairs...\")\n",
        "    high_overlap_pairs = []\n",
        "\n",
        "    for i in range(len(df) - 1):\n",
        "        input_text = str(df.iloc[i]['sentence']).strip()\n",
        "        response_text = str(df.iloc[i+1]['sentence']).strip()\n",
        "\n",
        "        if (15 < len(input_text) < 150 and 15 < len(response_text) < 150):\n",
        "            relatedness = calculate_semantic_relatedness(input_text, response_text)\n",
        "\n",
        "            if relatedness >= 0.1:  # At least 10% overlap\n",
        "                high_overlap_pairs.append({\n",
        "                    'input': input_text,\n",
        "                    'response': response_text,\n",
        "                    'type': 'high-overlap',\n",
        "                    'quality': 'high',\n",
        "                    'relatedness': relatedness\n",
        "                })\n",
        "\n",
        "    print(f\"  ✓ Found {len(high_overlap_pairs)} high-overlap pairs\")\n",
        "    all_pairs.extend(high_overlap_pairs)\n",
        "\n",
        "    # ========================================================================\n",
        "    # STRATEGY 3: Context-Response (2 sentences → 1)\n",
        "    # ========================================================================\n",
        "    print(\"\\n[3/5] Context-response pairs...\")\n",
        "    context_pairs = []\n",
        "\n",
        "    for i in range(len(df) - 2):\n",
        "        context = str(df.iloc[i]['sentence']).strip() + ' ' + str(df.iloc[i+1]['sentence']).strip()\n",
        "        response = str(df.iloc[i+2]['sentence']).strip()\n",
        "\n",
        "        if (20 < len(context) < 200 and 15 < len(response) < 150):\n",
        "            relatedness = calculate_semantic_relatedness(context, response)\n",
        "\n",
        "            if relatedness >= 0.05:  # Lowered threshold\n",
        "                context_pairs.append({\n",
        "                    'input': context,\n",
        "                    'response': response,\n",
        "                    'type': 'context-response',\n",
        "                    'quality': 'medium',\n",
        "                    'relatedness': relatedness\n",
        "                })\n",
        "\n",
        "    print(f\"  ✓ Found {len(context_pairs)} context-response pairs\")\n",
        "    all_pairs.extend(context_pairs)\n",
        "\n",
        "    # ========================================================================\n",
        "    # STRATEGY 4: Topic Continuation (LOW THRESHOLD)\n",
        "    # ========================================================================\n",
        "    print(\"\\n[4/5] Topic continuation pairs...\")\n",
        "    continuation_pairs = []\n",
        "\n",
        "    for i in range(len(df) - 1):\n",
        "        input_text = str(df.iloc[i]['sentence']).strip()\n",
        "        response_text = str(df.iloc[i+1]['sentence']).strip()\n",
        "\n",
        "        # Accept if reasonable length\n",
        "        if (10 < len(input_text) < 150 and 10 < len(response_text) < 150):\n",
        "            relatedness = calculate_semantic_relatedness(input_text, response_text)\n",
        "\n",
        "            # Very low threshold - just checking both are valid Urdu\n",
        "            if len(tokenize_urdu(input_text)) >= 3 and len(tokenize_urdu(response_text)) >= 3:\n",
        "                continuation_pairs.append({\n",
        "                    'input': input_text,\n",
        "                    'response': response_text,\n",
        "                    'type': 'continuation',\n",
        "                    'quality': 'medium',\n",
        "                    'relatedness': relatedness\n",
        "                })\n",
        "\n",
        "    print(f\"  ✓ Found {len(continuation_pairs)} continuation pairs\")\n",
        "    all_pairs.extend(continuation_pairs)\n",
        "\n",
        "    # ========================================================================\n",
        "    # STRATEGY 5: Sentence Splitting (CREATE MORE DATA)\n",
        "    # ========================================================================\n",
        "    print(\"\\n[5/5] Sentence splitting for augmentation...\")\n",
        "    split_pairs = []\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        text = str(df.iloc[i]['sentence']).strip()\n",
        "\n",
        "        # Split long sentences at punctuation\n",
        "        if len(text) > 100:\n",
        "            # Try to split at common punctuation\n",
        "            for punct in ['،', '۔', '؛']:\n",
        "                if punct in text:\n",
        "                    parts = text.split(punct)\n",
        "                    for j in range(len(parts) - 1):\n",
        "                        part1 = parts[j].strip()\n",
        "                        part2 = parts[j+1].strip()\n",
        "\n",
        "                        if (10 < len(part1) < 100 and 10 < len(part2) < 100):\n",
        "                            relatedness = calculate_semantic_relatedness(part1, part2)\n",
        "                            split_pairs.append({\n",
        "                                'input': part1,\n",
        "                                'response': part2,\n",
        "                                'type': 'split',\n",
        "                                'quality': 'medium',\n",
        "                                'relatedness': relatedness\n",
        "                            })\n",
        "                    break\n",
        "\n",
        "    print(f\"  ✓ Created {len(split_pairs)} split pairs\")\n",
        "    all_pairs.extend(split_pairs)\n",
        "\n",
        "    # ========================================================================\n",
        "    # REMOVE DUPLICATES\n",
        "    # ========================================================================\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"DEDUPLICATION\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    print(f\"Before deduplication: {len(all_pairs)} pairs\")\n",
        "\n",
        "    # Remove exact duplicates\n",
        "    seen = set()\n",
        "    unique_pairs = []\n",
        "    for pair in all_pairs:\n",
        "        key = (pair['input'], pair['response'])\n",
        "        if key not in seen:\n",
        "            seen.add(key)\n",
        "            unique_pairs.append(pair)\n",
        "\n",
        "    print(f\"After deduplication:  {len(unique_pairs)} pairs\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # SUMMARY\n",
        "    # ========================================================================\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"FINAL DATASET SUMMARY\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    df_pairs = pd.DataFrame(unique_pairs)\n",
        "\n",
        "    print(f\"\\nTotal pairs: {len(df_pairs)}\")\n",
        "    print(f\"\\nBreakdown by type:\")\n",
        "    print(df_pairs['type'].value_counts())\n",
        "\n",
        "    print(f\"\\nBreakdown by quality:\")\n",
        "    print(df_pairs['quality'].value_counts())\n",
        "\n",
        "    print(f\"\\nRelatedness statistics:\")\n",
        "    print(f\"  Min:    {df_pairs['relatedness'].min():.4f}\")\n",
        "    print(f\"  Max:    {df_pairs['relatedness'].max():.4f}\")\n",
        "    print(f\"  Mean:   {df_pairs['relatedness'].mean():.4f}\")\n",
        "    print(f\"  Median: {df_pairs['relatedness'].median():.4f}\")\n",
        "\n",
        "    # Show sample from each type\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"SAMPLES FROM EACH TYPE\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    for pair_type in df_pairs['type'].unique():\n",
        "        samples = df_pairs[df_pairs['type'] == pair_type].nlargest(2, 'relatedness')\n",
        "        print(f\"\\n--- {pair_type.upper()} ---\")\n",
        "        for _, row in samples.iterrows():\n",
        "            print(f\"Input:    {row['input'][:80]}...\")\n",
        "            print(f\"Response: {row['response'][:80]}...\")\n",
        "            print(f\"Relatedness: {row['relatedness']:.3f}\\n\")\n",
        "\n",
        "    return df_pairs\n",
        "\n",
        "# ============================================================================\n",
        "# CREATE DATASET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING BALANCED CONVERSATIONAL DATASET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "pairs_df = create_balanced_pairs(df, target_pairs=10000)\n",
        "\n",
        "# Keep only necessary columns\n",
        "text_data = pairs_df[['input', 'response']]\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"✓ Dataset ready with {len(text_data)} conversational pairs!\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Check if we have enough data\n",
        "if len(text_data) < 5000:\n",
        "    print(f\"\\n⚠️  WARNING: Only {len(text_data)} pairs found.\")\n",
        "    print(\"This is below the recommended 5,000 minimum.\")\n",
        "    print(\"Training will proceed but results may be limited.\")\n",
        "    print(\"\\nSuggestion: Consider using a larger Urdu corpus or different dataset.\")\n",
        "elif len(text_data) < 10000:\n",
        "    print(f\"\\n⚠️  Note: {len(text_data)} pairs is acceptable but more data would be better.\")\n",
        "else:\n",
        "    print(f\"\\n✓ Good: {len(text_data)} pairs is sufficient for training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXtnVpes0IWI",
        "outputId": "69d7a90c-e2f9-42b6-b132-f74cd8aa2f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building vocabulary from conversational pairs...\n",
            "Processing 17017 pairs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing sentences: 100%|██████████| 17017/17017 [00:03<00:00, 5224.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "VOCABULARY STATISTICS\n",
            "======================================================================\n",
            "Total vocabulary size: 10647\n",
            "Total unique words (excluding special tokens): 10643\n",
            "\n",
            "======================================================================\n",
            "MOST COMMON WORDS\n",
            "======================================================================\n",
            " 1. کی                   → 15206 occurrences\n",
            " 2. میں                  →  7616 occurrences\n",
            " 3. ہی                   →  6302 occurrences\n",
            " 4. کا                   →  5936 occurrences\n",
            " 5. ہی۔                  →  5528 occurrences\n",
            " 6. سی                   →  5475 occurrences\n",
            " 7. کو                   →  3760 occurrences\n",
            " 8. اس                   →  3483 occurrences\n",
            " 9. اور                  →  3417 occurrences\n",
            "10. یہ                   →  3148 occurrences\n",
            "11. نہیں                 →  2813 occurrences\n",
            "12. تو                   →  2572 occurrences\n",
            "13. نی                   →  2491 occurrences\n",
            "14. بھی                  →  2425 occurrences\n",
            "15. پر                   →  2398 occurrences\n",
            "16. کیا                  →  2237 occurrences\n",
            "17. ہیں۔                 →  2229 occurrences\n",
            "18. ایک                  →  2154 occurrences\n",
            "19. ہیں                  →  2065 occurrences\n",
            "20. وہ                   →  1995 occurrences\n",
            "\n",
            "======================================================================\n",
            "SPECIAL TOKENS\n",
            "======================================================================\n",
            "  <PAD>      → Index: 0\n",
            "  <SOS>      → Index: 1\n",
            "  <EOS>      → Index: 2\n",
            "  <UNK>      → Index: 3\n",
            "\n",
            "======================================================================\n",
            "VOCABULARY COVERAGE\n",
            "======================================================================\n",
            "Total word occurrences: 290,636\n",
            "Top   10 words cover: 20.60% of all words\n",
            "Top   20 words cover: 28.64% of all words\n",
            "\n",
            "======================================================================\n",
            "✓ Vocabulary built successfully!\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 6: Build Vocabulary (Updated for Conversational Pairs)\n",
        "# ============================================================================\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.word2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n",
        "        self.idx2word = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n",
        "        self.word_count = {}\n",
        "        self.n_words = 4\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in tokenize_urdu(sentence):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.word2idx[word] = self.n_words\n",
        "            self.idx2word[self.n_words] = word\n",
        "            self.word_count[word] = 1\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word_count[word] += 1\n",
        "\n",
        "vocab = Vocabulary()\n",
        "print(\"Building vocabulary from conversational pairs...\")\n",
        "print(f\"Processing {len(text_data)} pairs...\")\n",
        "\n",
        "# Process both input and response from each pair\n",
        "for _, row in tqdm(text_data.iterrows(), desc=\"Processing sentences\", total=len(text_data)):\n",
        "    vocab.add_sentence(str(row['input']))\n",
        "    vocab.add_sentence(str(row['response']))\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"VOCABULARY STATISTICS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Total vocabulary size: {vocab.n_words}\")\n",
        "print(f\"Total unique words (excluding special tokens): {vocab.n_words - 4}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"MOST COMMON WORDS\")\n",
        "print(f\"{'='*70}\")\n",
        "common_words = sorted(vocab.word_count.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "for i, (word, count) in enumerate(common_words, 1):\n",
        "    print(f\"{i:2}. {word:20} → {count:5} occurrences\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SPECIAL TOKENS\")\n",
        "print(f\"{'='*70}\")\n",
        "for token, idx in vocab.word2idx.items():\n",
        "    if idx < 4:\n",
        "        print(f\"  {token:10} → Index: {idx}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"VOCABULARY COVERAGE\")\n",
        "print(f\"{'='*70}\")\n",
        "total_words = sum(vocab.word_count.values())\n",
        "print(f\"Total word occurrences: {total_words:,}\")\n",
        "\n",
        "# Calculate coverage of most common words\n",
        "cumulative_count = 0\n",
        "for i, (word, count) in enumerate(common_words, 1):\n",
        "    cumulative_count += count\n",
        "    coverage = (cumulative_count / total_words) * 100\n",
        "    if i in [10, 50, 100, 500]:\n",
        "        print(f\"Top {i:4} words cover: {coverage:.2f}% of all words\")\n",
        "    if i == len(common_words):\n",
        "        print(f\"Top {i:4} words cover: {coverage:.2f}% of all words\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"✓ Vocabulary built successfully!\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHWB5JLu0OSi",
        "outputId": "895629aa-b28c-41c2-95d6-6dc9e5bd6033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "QUALITY-AWARE SPAN CORRUPTION AUGMENTATION\n",
            "======================================================================\n",
            "\n",
            "Dataset statistics:\n",
            "  Original pairs: 17017\n",
            "  Vocabulary before sentinels: 10647\n",
            "  Vocabulary after sentinels: 10747\n",
            "Preserving all original pairs...\n",
            "Original pairs preserved: 17017\n",
            "\n",
            "Quality-aware augmentation:\n",
            "  High-quality pairs to augment: 727\n",
            "  Medium-quality pairs to augment: 2279\n",
            "\n",
            "Total pairs to corrupt: 3006\n",
            "Applying span corruption...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Corrupting: 100%|██████████| 3006/3006 [00:00<00:00, 13142.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Successfully created 2542 corrupted pairs\n",
            "\n",
            "======================================================================\n",
            "AUGMENTATION RESULTS\n",
            "======================================================================\n",
            "Original pairs:   17017\n",
            "Augmented pairs:  19559\n",
            "New pairs added:  +2542\n",
            "Increase:         14.9%\n",
            "\n",
            "======================================================================\n",
            "SPAN CORRUPTION EXAMPLES\n",
            "======================================================================\n",
            "\n",
            "--- Example 1 ---\n",
            "Corrupted:  وہ یہ <SENTINEL_0> ایشوریا نی جو بھی...\n",
            "Target:     وہ یہ ہے کہ ایشوریا نے جو بھی...\n",
            "\n",
            "--- Example 2 ---\n",
            "Corrupted:  اک بار ہی جی <SENTINEL_0> نہیں دیتی...\n",
            "Target:     اک بار ہی جی بھر کے سزا کیوں نہیں دیتے...\n",
            "\n",
            "--- Example 3 ---\n",
            "Corrupted:  <SENTINEL_0> چیزوں کا خیال نہیں ایا؟...\n",
            "Target:     تب انہیں ان چیزوں کا خیال نہیں آیا؟...\n",
            "\n",
            "--- Example 4 ---\n",
            "Corrupted:  کیا وہ بھی <SENTINEL_0> نیک مقصد کی لیی حوالہ زنداں ہیں؟...\n",
            "Target:     کیا وہ بھی کسی نیک مقصد کے لیے حوالۂ زنداں ہیں؟...\n",
            "\n",
            "--- Example 5 ---\n",
            "Corrupted:  تو پھر کپتان کوئی <SENTINEL_0> ہو...\n",
            "Target:     تو پھر کپتان کوئی بھی ہو...\n",
            "\n",
            "======================================================================\n",
            "✓ Final dataset ready: 19559 pairs\n",
            "======================================================================\n",
            "\n",
            "Final Training Data:\n",
            "  Total pairs: 19,559\n",
            "  Expected train set (80%): ~15,647\n",
            "  Expected val set (10%): ~1,955\n",
            "  Expected test set (10%): ~1,955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 6B: OPTIMIZED - Span Corruption with Quality-Aware Augmentation\n",
        "# ============================================================================\n",
        "\n",
        "import random\n",
        "\n",
        "class OptimizedSpanCorruption:\n",
        "    \"\"\"\n",
        "    Span corruption that prioritizes high-quality pairs\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab, corruption_rate=0.15, mean_span_length=3):\n",
        "        self.vocab = vocab\n",
        "        self.corruption_rate = corruption_rate\n",
        "        self.mean_span_length = mean_span_length\n",
        "        self.sentinel_tokens = {}\n",
        "\n",
        "        # Add sentinel tokens\n",
        "        for i in range(100):\n",
        "            sentinel = f'<SENTINEL_{i}>'\n",
        "            if sentinel not in vocab.word2idx:\n",
        "                vocab.word2idx[sentinel] = vocab.n_words\n",
        "                vocab.idx2word[vocab.n_words] = sentinel\n",
        "                vocab.n_words += 1\n",
        "                self.sentinel_tokens[i] = vocab.n_words - 1\n",
        "\n",
        "    def corrupt_spans(self, text):\n",
        "        \"\"\"Apply span corruption\"\"\"\n",
        "        tokens = tokenize_urdu(text)\n",
        "\n",
        "        if len(tokens) < 5:\n",
        "            return None, None\n",
        "\n",
        "        # Calculate spans to corrupt\n",
        "        num_to_corrupt = max(1, int(len(tokens) * self.corruption_rate))\n",
        "\n",
        "        # Randomly select span starting positions\n",
        "        available_positions = list(range(len(tokens) - 1))\n",
        "        random.shuffle(available_positions)\n",
        "\n",
        "        corrupted_spans = []\n",
        "        tokens_to_corrupt = set()\n",
        "        sentinel_id = 0\n",
        "\n",
        "        for start in available_positions:\n",
        "            if len(tokens_to_corrupt) >= num_to_corrupt:\n",
        "                break\n",
        "\n",
        "            if start in tokens_to_corrupt:\n",
        "                continue\n",
        "\n",
        "            # Determine span length\n",
        "            span_length = min(\n",
        "                np.random.geometric(1.0 / self.mean_span_length),\n",
        "                len(tokens) - start,\n",
        "                4  # Max span\n",
        "            )\n",
        "\n",
        "            span_indices = list(range(start, min(start + span_length, len(tokens))))\n",
        "\n",
        "            if not any(idx in tokens_to_corrupt for idx in span_indices):\n",
        "                corrupted_spans.append((start, span_indices, sentinel_id))\n",
        "                tokens_to_corrupt.update(span_indices)\n",
        "                sentinel_id += 1\n",
        "\n",
        "        if not corrupted_spans:\n",
        "            return None, None\n",
        "\n",
        "        # Sort spans by position\n",
        "        corrupted_spans.sort(key=lambda x: x[0])\n",
        "\n",
        "        # Build corrupted input and target\n",
        "        corrupted_input = []\n",
        "        target_output = []\n",
        "\n",
        "        last_idx = 0\n",
        "        for start, span_indices, sent_id in corrupted_spans:\n",
        "            corrupted_input.extend(tokens[last_idx:start])\n",
        "            sentinel = f'<SENTINEL_{sent_id}>'\n",
        "            corrupted_input.append(sentinel)\n",
        "            target_output.append(sentinel)\n",
        "            target_output.extend([tokens[i] for i in span_indices])\n",
        "            last_idx = span_indices[-1] + 1\n",
        "\n",
        "        corrupted_input.extend(tokens[last_idx:])\n",
        "\n",
        "        if len(corrupted_input) < 3 or len(target_output) < 2:\n",
        "            return None, None\n",
        "\n",
        "        return ' '.join(corrupted_input), ' '.join(target_output)\n",
        "\n",
        "    def augment_dataset(self, pairs_df, augmentation_ratio=0.2):\n",
        "        \"\"\"\n",
        "        Augment dataset with focus on high-quality pairs\n",
        "        \"\"\"\n",
        "        augmented_pairs = []\n",
        "\n",
        "        # Keep all original pairs\n",
        "        print(\"Preserving all original pairs...\")\n",
        "        for _, row in pairs_df.iterrows():\n",
        "            augmented_pairs.append({\n",
        "                'input': row['input'],\n",
        "                'response': row['response']\n",
        "            })\n",
        "\n",
        "        print(f\"Original pairs preserved: {len(pairs_df)}\")\n",
        "\n",
        "        # Separate by quality if available\n",
        "        if 'quality' in pairs_df.columns:\n",
        "            high_quality = pairs_df[pairs_df['quality'] == 'high']\n",
        "            medium_quality = pairs_df[pairs_df['quality'] == 'medium']\n",
        "\n",
        "            # Augment MORE high-quality pairs (40%)\n",
        "            num_high = int(len(high_quality) * 0.4)\n",
        "            # Augment FEWER medium-quality pairs (15%)\n",
        "            num_medium = int(len(medium_quality) * 0.15)\n",
        "\n",
        "            samples_to_corrupt = pd.concat([\n",
        "                high_quality.sample(n=min(num_high, len(high_quality)), random_state=42),\n",
        "                medium_quality.sample(n=min(num_medium, len(medium_quality)), random_state=42)\n",
        "            ])\n",
        "\n",
        "            print(f\"\\nQuality-aware augmentation:\")\n",
        "            print(f\"  High-quality pairs to augment: {min(num_high, len(high_quality))}\")\n",
        "            print(f\"  Medium-quality pairs to augment: {min(num_medium, len(medium_quality))}\")\n",
        "        else:\n",
        "            # Fallback: uniform sampling\n",
        "            num_to_augment = int(len(pairs_df) * augmentation_ratio)\n",
        "            samples_to_corrupt = pairs_df.sample(n=min(num_to_augment, len(pairs_df)), random_state=42)\n",
        "            print(f\"\\nUniform augmentation: {len(samples_to_corrupt)} pairs\")\n",
        "\n",
        "        print(f\"\\nTotal pairs to corrupt: {len(samples_to_corrupt)}\")\n",
        "        print(\"Applying span corruption...\")\n",
        "\n",
        "        successful_corruptions = 0\n",
        "\n",
        "        for _, row in tqdm(samples_to_corrupt.iterrows(), desc=\"Corrupting\", total=len(samples_to_corrupt)):\n",
        "            # Corrupt the input\n",
        "            corrupted_input, corruption_target = self.corrupt_spans(row['input'])\n",
        "\n",
        "            if corrupted_input and corruption_target:\n",
        "                # Denoising task: corrupted input → original input\n",
        "                augmented_pairs.append({\n",
        "                    'input': corrupted_input,\n",
        "                    'response': row['input']  # Reconstruct original\n",
        "                })\n",
        "                successful_corruptions += 1\n",
        "\n",
        "        print(f\"✓ Successfully created {successful_corruptions} corrupted pairs\")\n",
        "\n",
        "        return pd.DataFrame(augmented_pairs)\n",
        "\n",
        "# ============================================================================\n",
        "# RUN SPAN CORRUPTION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"QUALITY-AWARE SPAN CORRUPTION AUGMENTATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "span_corruptor = OptimizedSpanCorruption(vocab, corruption_rate=0.15, mean_span_length=3)\n",
        "\n",
        "print(f\"\\nDataset statistics:\")\n",
        "print(f\"  Original pairs: {len(text_data)}\")\n",
        "print(f\"  Vocabulary before sentinels: {vocab.n_words - 100}\")\n",
        "print(f\"  Vocabulary after sentinels: {vocab.n_words}\")\n",
        "\n",
        "# Check if we have quality information\n",
        "if 'quality' in pairs_df.columns:\n",
        "    # Pass the full dataframe with quality info\n",
        "    text_data_augmented = span_corruptor.augment_dataset(pairs_df, augmentation_ratio=0.2)\n",
        "else:\n",
        "    # Fallback without quality info\n",
        "    text_data_augmented = span_corruptor.augment_dataset(text_data, augmentation_ratio=0.2)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"AUGMENTATION RESULTS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Original pairs:   {len(text_data)}\")\n",
        "print(f\"Augmented pairs:  {len(text_data_augmented)}\")\n",
        "print(f\"New pairs added:  +{len(text_data_augmented) - len(text_data)}\")\n",
        "print(f\"Increase:         {((len(text_data_augmented) / len(text_data)) - 1) * 100:.1f}%\")\n",
        "\n",
        "# Show examples\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SPAN CORRUPTION EXAMPLES\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "corrupted_samples = text_data_augmented[text_data_augmented['input'].str.contains('SENTINEL', na=False)].head(5)\n",
        "\n",
        "for i, (idx, row) in enumerate(corrupted_samples.iterrows(), 1):\n",
        "    print(f\"\\n--- Example {i} ---\")\n",
        "    print(f\"Corrupted:  {row['input'][:100]}...\")\n",
        "    print(f\"Target:     {row['response'][:100]}...\")\n",
        "\n",
        "# Keep only input and response columns\n",
        "text_data = text_data_augmented[['input', 'response']]\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"✓ Final dataset ready: {len(text_data)} pairs\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Final statistics\n",
        "print(f\"\\nFinal Training Data:\")\n",
        "print(f\"  Total pairs: {len(text_data):,}\")\n",
        "print(f\"  Expected train set (80%): ~{int(len(text_data) * 0.8):,}\")\n",
        "print(f\"  Expected val set (10%): ~{int(len(text_data) * 0.1):,}\")\n",
        "print(f\"  Expected test set (10%): ~{int(len(text_data) * 0.1):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG6evFDz0TZ8",
        "outputId": "8bcc3176-8132-410e-8aa2-38795b5b7c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "SPLITTING CONVERSATIONAL PAIRS\n",
            "======================================================================\n",
            "Total conversational pairs: 19559\n",
            "\n",
            "======================================================================\n",
            "SPLIT STATISTICS\n",
            "======================================================================\n",
            "Training samples:   15647 (80.0%)\n",
            "Validation samples:  1956 (10.0%)\n",
            "Test samples:        1956 (10.0%)\n",
            "\n",
            "======================================================================\n",
            "SAMPLE FROM EACH SPLIT\n",
            "======================================================================\n",
            "\n",
            "--- TRAINING SET (Sample 1) ---\n",
            "Input:    بجلی نہیں چمکتی تو <SENTINEL_0>\n",
            "Response: بجلی نہیں چمکتی تو رک جاتا ہے۔\n",
            "\n",
            "--- VALIDATION SET (Sample 1) ---\n",
            "Input:    انہیں یہ بات سمجھنی چاہیے کہ لیڈر وژن سے بنتا ہے۔\n",
            "Response: اس طرح کی اور بھی فلمیں ہونی چاہئے\n",
            "\n",
            "--- TEST SET (Sample 1) ---\n",
            "Input:    جیسے پہلے تھے۔\n",
            "Response: بہت روتے ہیں۔\n",
            "\n",
            "======================================================================\n",
            "✓ Dataset split completed successfully!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 7: Dataset Split (80% Train, 10% Val, 10% Test)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"SPLITTING CONVERSATIONAL PAIRS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# text_data is already a DataFrame with 'input' and 'response' columns\n",
        "print(f\"Total conversational pairs: {len(text_data)}\")\n",
        "\n",
        "# Split: 80% train, 10% validation, 10% test\n",
        "train_data, temp_data = train_test_split(text_data, test_size=0.2, random_state=42)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SPLIT STATISTICS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Training samples:   {len(train_data):5} ({len(train_data)/len(text_data)*100:.1f}%)\")\n",
        "print(f\"Validation samples: {len(val_data):5} ({len(val_data)/len(text_data)*100:.1f}%)\")\n",
        "print(f\"Test samples:       {len(test_data):5} ({len(test_data)/len(text_data)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SAMPLE FROM EACH SPLIT\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "print(\"\\n--- TRAINING SET (Sample 1) ---\")\n",
        "sample_train = train_data.iloc[0]\n",
        "print(f\"Input:    {sample_train['input']}\")\n",
        "print(f\"Response: {sample_train['response']}\")\n",
        "\n",
        "print(\"\\n--- VALIDATION SET (Sample 1) ---\")\n",
        "sample_val = val_data.iloc[0]\n",
        "print(f\"Input:    {sample_val['input']}\")\n",
        "print(f\"Response: {sample_val['response']}\")\n",
        "\n",
        "print(\"\\n--- TEST SET (Sample 1) ---\")\n",
        "sample_test = test_data.iloc[0]\n",
        "print(f\"Input:    {sample_test['input']}\")\n",
        "print(f\"Response: {sample_test['response']}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"✓ Dataset split completed successfully!\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIYXaRkW0WSk",
        "outputId": "dd4d4932-c57d-42f9-d2be-5b568386b694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "DATASETS CREATED SUCCESSFULLY\n",
            "======================================================================\n",
            "Training dataset:   15647 pairs\n",
            "Validation dataset:  1956 pairs\n",
            "Test dataset:        1956 pairs\n",
            "\n",
            "======================================================================\n",
            "SAMPLE DATA POINT (Index 0)\n",
            "======================================================================\n",
            "\n",
            "Encoder Input shape:  torch.Size([50])\n",
            "Decoder Input shape:  torch.Size([50])\n",
            "Decoder Target shape: torch.Size([50])\n",
            "\n",
            "======================================================================\n",
            "DECODED SAMPLE\n",
            "======================================================================\n",
            "\n",
            "Original Input:   بجلی نہیں چمکتی تو <SENTINEL_0>\n",
            "Encoded Input:    بجلی نہیں چمکتی تو <SENTINEL_0>\n",
            "\n",
            "Original Response: بجلی نہیں چمکتی تو رک جاتا ہے۔\n",
            "Decoder Input:     بجلی نہیں چمکتی تو رک جاتا ہی۔\n",
            "Decoder Target:    بجلی نہیں چمکتی تو رک جاتا ہی۔\n",
            "\n",
            "======================================================================\n",
            "TOKEN SEQUENCES (First 15 tokens)\n",
            "======================================================================\n",
            "Encoder Input:  [1, 1791, 61, 4739, 138, 10647, 2, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Decoder Input:  [1, 1791, 61, 4739, 138, 4617, 1140, 36, 0, 0, 0, 0, 0, 0, 0]\n",
            "Decoder Target: [1791, 61, 4739, 138, 4617, 1140, 36, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "======================================================================\n",
            "✓ Dataset class updated for conversational pairs!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 8: PyTorch Dataset Class (Updated for Conversational Pairs)\n",
        "# ============================================================================\n",
        "class UrduConversationalDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for Urdu conversational pairs (input -> response)\n",
        "    Encoder receives input, Decoder generates response\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe, vocab, max_len=50):\n",
        "        self.data = dataframe.reset_index(drop=True)\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def tokenize_and_encode(self, text, add_sos=False, add_eos=False):\n",
        "        \"\"\"Tokenize text and convert to indices\"\"\"\n",
        "        tokens = tokenize_urdu(text)\n",
        "\n",
        "        # Convert to indices\n",
        "        indices = [self.vocab.word2idx.get(token, self.vocab.word2idx['<UNK>'])\n",
        "                   for token in tokens]\n",
        "\n",
        "        # Add special tokens\n",
        "        if add_sos:\n",
        "            indices = [self.vocab.word2idx['<SOS>']] + indices\n",
        "        if add_eos:\n",
        "            indices = indices + [self.vocab.word2idx['<EOS>']]\n",
        "\n",
        "        # Pad or truncate\n",
        "        if len(indices) < self.max_len:\n",
        "            indices += [self.vocab.word2idx['<PAD>']] * (self.max_len - len(indices))\n",
        "        else:\n",
        "            indices = indices[:self.max_len]\n",
        "\n",
        "        return indices\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get input and response texts\n",
        "        input_text = str(self.data.iloc[idx]['input'])\n",
        "        response_text = str(self.data.iloc[idx]['response'])\n",
        "\n",
        "        # Encoder input: Add SOS and EOS to input\n",
        "        encoder_input = self.tokenize_and_encode(input_text, add_sos=True, add_eos=True)\n",
        "\n",
        "        # Decoder input: Add SOS to response (used during training with teacher forcing)\n",
        "        decoder_input = self.tokenize_and_encode(response_text, add_sos=True, add_eos=False)\n",
        "\n",
        "        # Decoder target: Add EOS to response (what decoder should predict)\n",
        "        decoder_target = self.tokenize_and_encode(response_text, add_sos=False, add_eos=True)\n",
        "\n",
        "        return {\n",
        "            'encoder_input': torch.tensor(encoder_input, dtype=torch.long),\n",
        "            'decoder_input': torch.tensor(decoder_input, dtype=torch.long),\n",
        "            'decoder_target': torch.tensor(decoder_target, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = UrduConversationalDataset(train_data, vocab, max_len=50)\n",
        "val_dataset = UrduConversationalDataset(val_data, vocab, max_len=50)\n",
        "test_dataset = UrduConversationalDataset(test_data, vocab, max_len=50)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DATASETS CREATED SUCCESSFULLY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Training dataset:   {len(train_dataset):5} pairs\")\n",
        "print(f\"Validation dataset: {len(val_dataset):5} pairs\")\n",
        "print(f\"Test dataset:       {len(test_dataset):5} pairs\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SAMPLE DATA POINT (Index 0)\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "sample = train_dataset[0]\n",
        "print(f\"\\nEncoder Input shape:  {sample['encoder_input'].shape}\")\n",
        "print(f\"Decoder Input shape:  {sample['decoder_input'].shape}\")\n",
        "print(f\"Decoder Target shape: {sample['decoder_target'].shape}\")\n",
        "\n",
        "# Decode and show the actual text\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"DECODED SAMPLE\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "def decode_indices(indices, vocab):\n",
        "    \"\"\"Convert indices back to text\"\"\"\n",
        "    words = []\n",
        "    for idx in indices:\n",
        "        idx = idx.item() if torch.is_tensor(idx) else idx\n",
        "        if idx == vocab.word2idx['<PAD>']:\n",
        "            break\n",
        "        word = vocab.idx2word[idx]\n",
        "        if word not in ['<SOS>', '<EOS>', '<PAD>']:\n",
        "            words.append(word)\n",
        "    return ' '.join(words)\n",
        "\n",
        "encoder_text = decode_indices(sample['encoder_input'], vocab)\n",
        "decoder_input_text = decode_indices(sample['decoder_input'], vocab)\n",
        "decoder_target_text = decode_indices(sample['decoder_target'], vocab)\n",
        "\n",
        "print(f\"\\nOriginal Input:   {train_data.iloc[0]['input']}\")\n",
        "print(f\"Encoded Input:    {encoder_text}\")\n",
        "print(f\"\\nOriginal Response: {train_data.iloc[0]['response']}\")\n",
        "print(f\"Decoder Input:     {decoder_input_text}\")\n",
        "print(f\"Decoder Target:    {decoder_target_text}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"TOKEN SEQUENCES (First 15 tokens)\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Encoder Input:  {sample['encoder_input'][:15].tolist()}\")\n",
        "print(f\"Decoder Input:  {sample['decoder_input'][:15].tolist()}\")\n",
        "print(f\"Decoder Target: {sample['decoder_target'][:15].tolist()}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"✓ Dataset class updated for conversational pairs!\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75tZkHcD0d1Q",
        "outputId": "9fc47e64-7f7d-4d13-f239-a8f333d49bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positional Encoding defined!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 9: Positional Encoding\n",
        "# ============================================================================\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "#comment\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "print(\"Positional Encoding defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60A5Qwp_0dtx",
        "outputId": "8e50d222-a53a-43e7-8dbe-60e8b210b3bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformer Encoder Layer defined!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 10: Transformer Encoder Layer\n",
        "# ============================================================================\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, src_mask=None):\n",
        "        attn_output, _ = self.self_attn(x, x, x, key_padding_mask=src_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "\n",
        "        return x\n",
        "\n",
        "print(\"Transformer Encoder Layer defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eSuc4zd0i9V",
        "outputId": "9b114f08-5617-4998-c1c4-d2341ef03930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformer Decoder Layer defined!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 11: Transformer Decoder Layer\n",
        "# ============================================================================\n",
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
        "        self.cross_attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, tgt_mask=None, src_mask=None):\n",
        "        attn_output, _ = self.self_attn(x, x, x, attn_mask=tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        attn_output, _ = self.cross_attn(x, encoder_output, encoder_output, key_padding_mask=src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "\n",
        "        return x\n",
        "\n",
        "print(\"Transformer Decoder Layer defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAr_RecN0lhR",
        "outputId": "26d8fdbe-c8c2-4a9e-ff0e-cc5f3d5e8b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformer model defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 12: Complete Transformer Model\n",
        "# ============================================================================\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=256, n_heads=2, n_encoder_layers=2,\n",
        "                 n_decoder_layers=2, d_ff=512, dropout=0.1, max_len=50):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len, dropout)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            TransformerEncoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "            for _ in range(n_encoder_layers)\n",
        "        ])\n",
        "\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            TransformerDecoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "            for _ in range(n_decoder_layers)\n",
        "        ])\n",
        "\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = torch.triu(torch.ones(sz, sz), diagonal=1)\n",
        "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
        "        return mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask = (src == 0)  \n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt.size(1)).to(src.device)\n",
        "\n",
        "        src_emb = self.dropout(self.pos_encoding(self.embedding(src) * math.sqrt(self.d_model)))\n",
        "        encoder_output = src_emb\n",
        "        for layer in self.encoder_layers:\n",
        "            encoder_output = layer(encoder_output, src_mask)\n",
        "\n",
        "        tgt_emb = self.dropout(self.pos_encoding(self.embedding(tgt) * math.sqrt(self.d_model)))\n",
        "        decoder_output = tgt_emb\n",
        "        for layer in self.decoder_layers:\n",
        "            decoder_output = layer(decoder_output, encoder_output, tgt_mask, src_mask)\n",
        "\n",
        "        output = self.fc_out(decoder_output)\n",
        "        return output\n",
        "\n",
        "print(\"Transformer model defined successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74QQ56Tm0pXH",
        "outputId": "54dc4a7f-97f1-418a-fbc3-bcd63c64a527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "OPTIMIZED TRAINING CONFIGURATION\n",
            "======================================================================\n",
            "\n",
            "Hyperparameters:\n",
            "  Batch Size:        32\n",
            "  Learning Rate:     0.0002\n",
            "  Num Epochs:        35\n",
            "  Embedding Dim:     384\n",
            "  Attention Heads:   6\n",
            "  Encoder Layers:    2\n",
            "  Decoder Layers:    2\n",
            "  Dropout:           0.2\n",
            "  Max Sequence Len:  50\n",
            "\n",
            "DataLoaders created:\n",
            "  Train batches: 489\n",
            "  Val batches:   62\n",
            "\n",
            "Model Statistics:\n",
            "  Total parameters:     16,546,555\n",
            "  Trainable parameters: 16,546,555\n",
            "  Model size (approx):  63.12 MB\n",
            "\n",
            "Optimizer: Adam with β=(0.9, 0.98)\n",
            "Loss: CrossEntropyLoss with label_smoothing=0.1\n",
            "Scheduler: ReduceLROnPlateau (factor=0.5, patience=3)\n",
            "\n",
            "======================================================================\n",
            "✓ Training configuration complete!\n",
            "======================================================================\n",
            "\n",
            "Running sanity check...\n",
            "✓ Model forward pass successful!\n",
            "  Batch size:     32\n",
            "  Sequence len:   50\n",
            "  Output shape:   torch.Size([32, 50, 10747])\n",
            "  Expected:       [32, 50, 10747]\n",
            "\n",
            "======================================================================\n",
            "Ready to start training!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 13: OPTIMIZED TRAINING CONFIGURATION (~20K PAIRS) - FIXED\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"OPTIMIZED TRAINING CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Hyperparameters optimized for your dataset size\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-4  # Lower for stability\n",
        "NUM_EPOCHS = 35       # More epochs since we have good data\n",
        "D_MODEL = 384         # Medium size (good balance)\n",
        "N_HEADS = 2           # Must divide D_MODEL evenly (384/6=64)\n",
        "N_ENCODER_LAYERS = 2\n",
        "N_DECODER_LAYERS = 2\n",
        "DROPOUT = 0.2\n",
        "MAX_LEN = 50\n",
        "\n",
        "print(\"\\nHyperparameters:\")\n",
        "print(f\"  Batch Size:        {BATCH_SIZE}\")\n",
        "print(f\"  Learning Rate:     {LEARNING_RATE}\")\n",
        "print(f\"  Num Epochs:        {NUM_EPOCHS}\")\n",
        "print(f\"  Embedding Dim:     {D_MODEL}\")\n",
        "print(f\"  Attention Heads:   {N_HEADS}\")\n",
        "print(f\"  Encoder Layers:    {N_ENCODER_LAYERS}\")\n",
        "print(f\"  Decoder Layers:    {N_DECODER_LAYERS}\")\n",
        "print(f\"  Dropout:           {DROPOUT}\")\n",
        "print(f\"  Max Sequence Len:  {MAX_LEN}\")\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"\\nDataLoaders created:\")\n",
        "print(f\"  Train batches: {len(train_loader)}\")\n",
        "print(f\"  Val batches:   {len(val_loader)}\")\n",
        "\n",
        "# Initialize model\n",
        "model = Transformer(\n",
        "    vocab_size=vocab.n_words,\n",
        "    d_model=D_MODEL,\n",
        "    n_heads=N_HEADS,\n",
        "    n_encoder_layers=N_ENCODER_LAYERS,\n",
        "    n_decoder_layers=N_DECODER_LAYERS,\n",
        "    d_ff=D_MODEL * 4,  # 1536\n",
        "    dropout=DROPOUT,\n",
        "    max_len=MAX_LEN\n",
        ").to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nModel Statistics:\")\n",
        "print(f\"  Total parameters:     {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"  Model size (approx):  {total_params * 4 / (1024**2):.2f} MB\")\n",
        "\n",
        "# Loss with label smoothing (helps with generalization)\n",
        "criterion = nn.CrossEntropyLoss(\n",
        "    ignore_index=vocab.word2idx['<PAD>'],\n",
        "    label_smoothing=0.1\n",
        ")\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    betas=(0.9, 0.98),\n",
        "    eps=1e-9\n",
        ")\n",
        "\n",
        "# Learning rate scheduler (reduces LR when validation plateaus)\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# FIX: Remove 'verbose' parameter\n",
        "scheduler = ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "print(f\"\\nOptimizer: Adam with β=(0.9, 0.98)\")\n",
        "print(f\"Loss: CrossEntropyLoss with label_smoothing=0.1\")\n",
        "print(f\"Scheduler: ReduceLROnPlateau (factor=0.5, patience=3)\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"✓ Training configuration complete!\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Quick sanity check\n",
        "print(f\"\\nRunning sanity check...\")\n",
        "sample_batch = next(iter(train_loader))\n",
        "encoder_input = sample_batch['encoder_input'].to(device)\n",
        "decoder_input = sample_batch['decoder_input'].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(encoder_input, decoder_input)\n",
        "\n",
        "print(f\"✓ Model forward pass successful!\")\n",
        "print(f\"  Batch size:     {encoder_input.shape[0]}\")\n",
        "print(f\"  Sequence len:   {encoder_input.shape[1]}\")\n",
        "print(f\"  Output shape:   {output.shape}\")\n",
        "print(f\"  Expected:       [{BATCH_SIZE}, {MAX_LEN}, {vocab.n_words}]\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"Ready to start training!\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixOw8yUD0tI9",
        "outputId": "c817f459-7fbe-42c9-f66e-8daa68d8262a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "✓ Training functions updated for conversational pairs!\n",
            "======================================================================\n",
            "\n",
            "Key changes:\n",
            "  • Extracts encoder_input, decoder_input, decoder_target from batch dictionary\n",
            "  • Model receives: model(encoder_input, decoder_input)\n",
            "  • Loss calculated against: decoder_target\n",
            "  • Gradient clipping applied to prevent exploding gradients\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 14: Training Functions (Updated for Conversational Dataset)\n",
        "# ============================================================================\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        # Extract data from dictionary\n",
        "        encoder_input = batch['encoder_input'].to(device)\n",
        "        decoder_input = batch['decoder_input'].to(device)\n",
        "        decoder_target = batch['decoder_target'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: encoder gets input, decoder gets response prefix\n",
        "        output = model(encoder_input, decoder_input)\n",
        "\n",
        "        # Calculate loss (ignore padding tokens)\n",
        "        loss = criterion(output.reshape(-1, vocab.n_words), decoder_target.reshape(-1))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    return total_loss / num_batches\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    \"\"\"Evaluate on validation/test set\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            # Extract data from dictionary\n",
        "            encoder_input = batch['encoder_input'].to(device)\n",
        "            decoder_input = batch['decoder_input'].to(device)\n",
        "            decoder_target = batch['decoder_target'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(encoder_input, decoder_input)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(output.reshape(-1, vocab.n_words), decoder_target.reshape(-1))\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "    return total_loss / num_batches\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"✓ Training functions updated for conversational pairs!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nKey changes:\")\n",
        "print(\"  • Extracts encoder_input, decoder_input, decoder_target from batch dictionary\")\n",
        "print(\"  • Model receives: model(encoder_input, decoder_input)\")\n",
        "print(\"  • Loss calculated against: decoder_target\")\n",
        "print(\"  • Gradient clipping applied to prevent exploding gradients\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzVkTfgO0viA",
        "outputId": "2e1d5312-ff53-428c-c88d-eeb3ed8c8c91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "STARTING TRAINING\n",
            "======================================================================\n",
            "Total epochs: 35\n",
            "Training samples: 15647\n",
            "Validation samples: 1956\n",
            "Device: cuda\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Epoch 1/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:24<00:00, 19.91it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 55.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       6.8790\n",
            "Val Loss:         6.4495\n",
            "Train Perplexity: 971.62\n",
            "Val Perplexity:   632.41\n",
            "Epoch Time:       25.67s\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 6.4495 (↓ inf)\n",
            "Val Perplexity: 632.41\n",
            "\n",
            "Estimated time remaining: 14.5 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 2/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:24<00:00, 20.13it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 58.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       6.3587\n",
            "Val Loss:         6.1226\n",
            "Train Perplexity: 577.49\n",
            "Val Perplexity:   456.03\n",
            "Epoch Time:       25.36s\n",
            "Train Δ:          +0.5203\n",
            "Val Δ:            +0.3270\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 6.1226 (↓ 0.3270)\n",
            "Val Perplexity: 456.03\n",
            "\n",
            "Estimated time remaining: 14.0 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 3/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.33it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 50.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       6.0539\n",
            "Val Loss:         5.8987\n",
            "Train Perplexity: 425.78\n",
            "Val Perplexity:   364.57\n",
            "Epoch Time:       26.55s\n",
            "Train Δ:          +0.3048\n",
            "Val Δ:            +0.2239\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 5.8987 (↓ 0.2239)\n",
            "Val Perplexity: 364.57\n",
            "\n",
            "Estimated time remaining: 13.8 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 4/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.30it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       5.8208\n",
            "Val Loss:         5.7352\n",
            "Train Perplexity: 337.25\n",
            "Val Perplexity:   309.58\n",
            "Epoch Time:       26.46s\n",
            "Train Δ:          +0.2331\n",
            "Val Δ:            +0.1635\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 5.7352 (↓ 0.1635)\n",
            "Val Perplexity: 309.58\n",
            "\n",
            "Estimated time remaining: 13.4 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 5/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.02it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 54.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       5.6284\n",
            "Val Loss:         5.6010\n",
            "Train Perplexity: 278.21\n",
            "Val Perplexity:   270.71\n",
            "Epoch Time:       26.86s\n",
            "Train Δ:          +0.1924\n",
            "Val Δ:            +0.1342\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 5.6010 (↓ 0.1342)\n",
            "Val Perplexity: 270.71\n",
            "\n",
            "Estimated time remaining: 13.1 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 6/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.16it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       5.4627\n",
            "Val Loss:         5.4937\n",
            "Train Perplexity: 235.74\n",
            "Val Perplexity:   243.15\n",
            "Epoch Time:       26.62s\n",
            "Train Δ:          +0.1657\n",
            "Val Δ:            +0.1074\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 5.4937 (↓ 0.1074)\n",
            "Val Perplexity: 243.15\n",
            "\n",
            "Estimated time remaining: 12.7 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 7/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.37it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 49.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       5.3123\n",
            "Val Loss:         5.3883\n",
            "Train Perplexity: 202.81\n",
            "Val Perplexity:   218.83\n",
            "Epoch Time:       26.50s\n",
            "Train Δ:          +0.1505\n",
            "Val Δ:            +0.1054\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 5.3883 (↓ 0.1054)\n",
            "Val Perplexity: 218.83\n",
            "\n",
            "Estimated time remaining: 12.3 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 8/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.25it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       5.1804\n",
            "Val Loss:         5.3029\n",
            "Train Perplexity: 177.76\n",
            "Val Perplexity:   200.91\n",
            "Epoch Time:       26.52s\n",
            "Train Δ:          +0.1318\n",
            "Val Δ:            +0.0854\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 5.3029 (↓ 0.0854)\n",
            "Val Perplexity: 200.91\n",
            "\n",
            "Estimated time remaining: 11.8 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 9/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.27it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       5.0557\n",
            "Val Loss:         5.2515\n",
            "Train Perplexity: 156.91\n",
            "Val Perplexity:   190.86\n",
            "Epoch Time:       26.48s\n",
            "Train Δ:          +0.1248\n",
            "Val Δ:            +0.0513\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 5.2515 (↓ 0.0513)\n",
            "Val Perplexity: 190.86\n",
            "\n",
            "Estimated time remaining: 11.4 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 10/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.35it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 57.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.9474\n",
            "Val Loss:         5.1610\n",
            "Train Perplexity: 140.80\n",
            "Val Perplexity:   174.33\n",
            "Epoch Time:       26.37s\n",
            "Train Δ:          +0.1083\n",
            "Val Δ:            +0.0906\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 5.1610 (↓ 0.0906)\n",
            "Val Perplexity: 174.33\n",
            "\n",
            "Estimated time remaining: 11.0 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 11/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.34it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 54.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.8395\n",
            "Val Loss:         5.1095\n",
            "Train Perplexity: 126.40\n",
            "Val Perplexity:   165.58\n",
            "Epoch Time:       26.44s\n",
            "Train Δ:          +0.1079\n",
            "Val Δ:            +0.0515\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 5.1095 (↓ 0.0515)\n",
            "Val Perplexity: 165.58\n",
            "\n",
            "Estimated time remaining: 10.5 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 12/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.18it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.7399\n",
            "Val Loss:         5.0460\n",
            "Train Perplexity: 114.42\n",
            "Val Perplexity:   155.40\n",
            "Epoch Time:       26.60s\n",
            "Train Δ:          +0.0996\n",
            "Val Δ:            +0.0634\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 5.0460 (↓ 0.0634)\n",
            "Val Perplexity: 155.40\n",
            "\n",
            "Estimated time remaining: 10.1 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 13/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.23it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 55.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.6509\n",
            "Val Loss:         4.9758\n",
            "Train Perplexity: 104.68\n",
            "Val Perplexity:   144.86\n",
            "Epoch Time:       26.55s\n",
            "Train Δ:          +0.0890\n",
            "Val Δ:            +0.0702\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.9758 (↓ 0.0702)\n",
            "Val Perplexity: 144.86\n",
            "\n",
            "Estimated time remaining: 9.7 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 14/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.25it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 55.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.5626\n",
            "Val Loss:         4.9349\n",
            "Train Perplexity: 95.83\n",
            "Val Perplexity:   139.06\n",
            "Epoch Time:       26.52s\n",
            "Train Δ:          +0.0883\n",
            "Val Δ:            +0.0409\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.9349 (↓ 0.0409)\n",
            "Val Perplexity: 139.06\n",
            "\n",
            "Estimated time remaining: 9.2 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 15/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.27it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.4855\n",
            "Val Loss:         4.8836\n",
            "Train Perplexity: 88.73\n",
            "Val Perplexity:   132.10\n",
            "Epoch Time:       26.49s\n",
            "Train Δ:          +0.0770\n",
            "Val Δ:            +0.0514\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.8836 (↓ 0.0514)\n",
            "Val Perplexity: 132.10\n",
            "\n",
            "Estimated time remaining: 8.8 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 16/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.26it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 54.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.4101\n",
            "Val Loss:         4.8469\n",
            "Train Perplexity: 82.27\n",
            "Val Perplexity:   127.35\n",
            "Epoch Time:       26.55s\n",
            "Train Δ:          +0.0755\n",
            "Val Δ:            +0.0367\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.8469 (↓ 0.0367)\n",
            "Val Perplexity: 127.35\n",
            "\n",
            "Estimated time remaining: 8.4 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 17/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.23it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 55.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.3365\n",
            "Val Loss:         4.7989\n",
            "Train Perplexity: 76.44\n",
            "Val Perplexity:   121.37\n",
            "Epoch Time:       26.57s\n",
            "Train Δ:          +0.0735\n",
            "Val Δ:            +0.0480\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.7989 (↓ 0.0480)\n",
            "Val Perplexity: 121.37\n",
            "\n",
            "Estimated time remaining: 7.9 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 18/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.25it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 55.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.2664\n",
            "Val Loss:         4.7660\n",
            "Train Perplexity: 71.27\n",
            "Val Perplexity:   117.45\n",
            "Epoch Time:       26.53s\n",
            "Train Δ:          +0.0701\n",
            "Val Δ:            +0.0328\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.7660 (↓ 0.0328)\n",
            "Val Perplexity: 117.45\n",
            "\n",
            "Estimated time remaining: 7.5 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 19/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.34it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.2073\n",
            "Val Loss:         4.7333\n",
            "Train Perplexity: 67.18\n",
            "Val Perplexity:   113.67\n",
            "Epoch Time:       26.40s\n",
            "Train Δ:          +0.0591\n",
            "Val Δ:            +0.0327\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.7333 (↓ 0.0327)\n",
            "Val Perplexity: 113.67\n",
            "\n",
            "Estimated time remaining: 7.0 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 20/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.31it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 49.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.1449\n",
            "Val Loss:         4.7140\n",
            "Train Perplexity: 63.11\n",
            "Val Perplexity:   111.49\n",
            "Epoch Time:       26.59s\n",
            "Train Δ:          +0.0624\n",
            "Val Δ:            +0.0194\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.7140 (↓ 0.0194)\n",
            "Val Perplexity: 111.49\n",
            "\n",
            "Estimated time remaining: 6.6 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 21/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.32it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.0861\n",
            "Val Loss:         4.6643\n",
            "Train Perplexity: 59.51\n",
            "Val Perplexity:   106.09\n",
            "Epoch Time:       26.41s\n",
            "Train Δ:          +0.0588\n",
            "Val Δ:            +0.0496\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.6643 (↓ 0.0496)\n",
            "Val Perplexity: 106.09\n",
            "\n",
            "Estimated time remaining: 6.2 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 22/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.31it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       4.0338\n",
            "Val Loss:         4.6323\n",
            "Train Perplexity: 56.47\n",
            "Val Perplexity:   102.75\n",
            "Epoch Time:       26.43s\n",
            "Train Δ:          +0.0523\n",
            "Val Δ:            +0.0321\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.6323 (↓ 0.0321)\n",
            "Val Perplexity: 102.75\n",
            "\n",
            "Estimated time remaining: 5.7 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 23/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.27it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 55.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.9768\n",
            "Val Loss:         4.6049\n",
            "Train Perplexity: 53.34\n",
            "Val Perplexity:   99.98\n",
            "Epoch Time:       26.50s\n",
            "Train Δ:          +0.0570\n",
            "Val Δ:            +0.0273\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.6049 (↓ 0.0273)\n",
            "Val Perplexity: 99.98\n",
            "\n",
            "Estimated time remaining: 5.3 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 24/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.24it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 49.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.9276\n",
            "Val Loss:         4.5926\n",
            "Train Perplexity: 50.78\n",
            "Val Perplexity:   98.75\n",
            "Epoch Time:       26.67s\n",
            "Train Δ:          +0.0492\n",
            "Val Δ:            +0.0123\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.5926 (↓ 0.0123)\n",
            "Val Perplexity: 98.75\n",
            "\n",
            "Estimated time remaining: 4.8 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 25/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.23it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 55.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.8864\n",
            "Val Loss:         4.5677\n",
            "Train Perplexity: 48.73\n",
            "Val Perplexity:   96.33\n",
            "Epoch Time:       26.54s\n",
            "Train Δ:          +0.0412\n",
            "Val Δ:            +0.0249\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.5677 (↓ 0.0249)\n",
            "Val Perplexity: 96.33\n",
            "\n",
            "Estimated time remaining: 4.4 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 26/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.25it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.8410\n",
            "Val Loss:         4.5463\n",
            "Train Perplexity: 46.57\n",
            "Val Perplexity:   94.29\n",
            "Epoch Time:       26.51s\n",
            "Train Δ:          +0.0454\n",
            "Val Δ:            +0.0214\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.5463 (↓ 0.0214)\n",
            "Val Perplexity: 94.29\n",
            "\n",
            "Estimated time remaining: 4.0 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 27/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.28it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.7941\n",
            "Val Loss:         4.5367\n",
            "Train Perplexity: 44.44\n",
            "Val Perplexity:   93.38\n",
            "Epoch Time:       26.47s\n",
            "Train Δ:          +0.0469\n",
            "Val Δ:            +0.0096\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.5367 (↓ 0.0096)\n",
            "Val Perplexity: 93.38\n",
            "\n",
            "Estimated time remaining: 3.5 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 28/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.26it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 53.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.7576\n",
            "Val Loss:         4.5239\n",
            "Train Perplexity: 42.85\n",
            "Val Perplexity:   92.19\n",
            "Epoch Time:       26.56s\n",
            "Train Δ:          +0.0365\n",
            "Val Δ:            +0.0128\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.5239 (↓ 0.0128)\n",
            "Val Perplexity: 92.19\n",
            "\n",
            "Estimated time remaining: 3.1 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 29/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.19it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 55.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.7201\n",
            "Val Loss:         4.5004\n",
            "Train Perplexity: 41.27\n",
            "Val Perplexity:   90.05\n",
            "Epoch Time:       26.61s\n",
            "Train Δ:          +0.0375\n",
            "Val Δ:            +0.0235\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.5004 (↓ 0.0235)\n",
            "Val Perplexity: 90.05\n",
            "\n",
            "Estimated time remaining: 2.6 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 30/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.25it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.6779\n",
            "Val Loss:         4.4961\n",
            "Train Perplexity: 39.56\n",
            "Val Perplexity:   89.66\n",
            "Epoch Time:       26.51s\n",
            "Train Δ:          +0.0422\n",
            "Val Δ:            +0.0043\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.4961 (↓ 0.0043)\n",
            "Val Perplexity: 89.66\n",
            "\n",
            "Estimated time remaining: 2.2 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 31/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.28it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.6430\n",
            "Val Loss:         4.4797\n",
            "Train Perplexity: 38.21\n",
            "Val Perplexity:   88.21\n",
            "Epoch Time:       26.47s\n",
            "Train Δ:          +0.0348\n",
            "Val Δ:            +0.0163\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.4797 (↓ 0.0163)\n",
            "Val Perplexity: 88.21\n",
            "\n",
            "Estimated time remaining: 1.8 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 32/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.24it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.6047\n",
            "Val Loss:         4.4630\n",
            "Train Perplexity: 36.77\n",
            "Val Perplexity:   86.75\n",
            "Epoch Time:       26.53s\n",
            "Train Δ:          +0.0383\n",
            "Val Δ:            +0.0167\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.4630 (↓ 0.0167)\n",
            "Val Perplexity: 86.75\n",
            "\n",
            "Estimated time remaining: 1.3 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 33/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.23it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 51.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.5726\n",
            "Val Loss:         4.4647\n",
            "Train Perplexity: 35.61\n",
            "Val Perplexity:   86.90\n",
            "Epoch Time:       26.65s\n",
            "Train Δ:          +0.0322\n",
            "Val Δ:            -0.0017\n",
            "\n",
            "No improvement for 1/7 epoch(s)\n",
            "\n",
            "Estimated time remaining: 0.9 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 34/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.27it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.5428\n",
            "Val Loss:         4.4515\n",
            "Train Perplexity: 34.56\n",
            "Val Perplexity:   85.76\n",
            "Epoch Time:       26.49s\n",
            "Train Δ:          +0.0298\n",
            "Val Δ:            +0.0132\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.4515 (↓ 0.0115)\n",
            "Val Perplexity: 85.76\n",
            "\n",
            "Estimated time remaining: 0.4 minutes\n",
            "\n",
            "======================================================================\n",
            "Epoch 35/35\n",
            "======================================================================\n",
            "Learning Rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 489/489 [00:25<00:00, 19.23it/s]\n",
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 56.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EPOCH RESULTS\n",
            "======================================================================\n",
            "Train Loss:       3.5043\n",
            "Val Loss:         4.4488\n",
            "Train Perplexity: 33.26\n",
            "Val Perplexity:   85.52\n",
            "Epoch Time:       26.54s\n",
            "Train Δ:          +0.0385\n",
            "Val Δ:            +0.0027\n",
            "\n",
            "======================================================================\n",
            "✓ BEST MODEL SAVED!\n",
            "======================================================================\n",
            "Val Loss: 4.4488 (↓ 0.0027)\n",
            "Val Perplexity: 85.52\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETED!\n",
            "======================================================================\n",
            "Total training time: 15.68 minutes\n",
            "Epochs trained: 35\n",
            "Average time per epoch: 26.88s\n",
            "\n",
            "Best Results:\n",
            "  Best Val Loss: 4.4488\n",
            "  Best Val Perplexity: 85.52\n",
            "  Best Epoch: 35\n",
            "\n",
            "Final Results:\n",
            "  Final Train Loss: 3.5043\n",
            "  Final Val Loss: 4.4488\n",
            "\n",
            "Model saved as: best_urdu_transformer.pt\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 15: IMPROVED TRAINING LOOP\n",
        "# ============================================================================\n",
        "import time\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Device: {device}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "learning_rates = []\n",
        "epoch_times = []\n",
        "\n",
        "# Early stopping\n",
        "patience = 7\n",
        "patience_counter = 0\n",
        "\n",
        "training_start_time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # Training\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "    # Validation\n",
        "    val_loss = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    # Step scheduler (reduce LR on plateau)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Calculate epoch time\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    epoch_times.append(epoch_time)\n",
        "\n",
        "    # Store metrics\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    learning_rates.append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    # Calculate perplexity\n",
        "    train_ppl = math.exp(min(train_loss, 10))\n",
        "    val_ppl = math.exp(min(val_loss, 10))\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"EPOCH RESULTS\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Train Loss:       {train_loss:.4f}\")\n",
        "    print(f\"Val Loss:         {val_loss:.4f}\")\n",
        "    print(f\"Train Perplexity: {train_ppl:.2f}\")\n",
        "    print(f\"Val Perplexity:   {val_ppl:.2f}\")\n",
        "    print(f\"Epoch Time:       {epoch_time:.2f}s\")\n",
        "\n",
        "    # Calculate improvement\n",
        "    if epoch > 0:\n",
        "        train_improvement = train_losses[-2] - train_loss\n",
        "        val_improvement = val_losses[-2] - val_loss\n",
        "        print(f\"Train Δ:          {train_improvement:+.4f}\")\n",
        "        print(f\"Val Δ:            {val_improvement:+.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        improvement = best_val_loss - val_loss\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'vocab': vocab,\n",
        "            'hyperparameters': {\n",
        "                'd_model': D_MODEL,\n",
        "                'n_heads': N_HEADS,\n",
        "                'n_encoder_layers': N_ENCODER_LAYERS,\n",
        "                'n_decoder_layers': N_DECODER_LAYERS,\n",
        "                'dropout': DROPOUT,\n",
        "                'max_len': MAX_LEN,\n",
        "                'vocab_size': vocab.n_words,\n",
        "                'batch_size': BATCH_SIZE,\n",
        "                'learning_rate': LEARNING_RATE\n",
        "            }\n",
        "        }, 'best_urdu_transformer.pt')\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"✓ BEST MODEL SAVED!\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} (↓ {improvement:.4f})\")\n",
        "        print(f\"Val Perplexity: {val_ppl:.2f}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"\\nNo improvement for {patience_counter}/{patience} epoch(s)\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(\"⚠️  EARLY STOPPING TRIGGERED!\")\n",
        "            print(f\"{'='*70}\")\n",
        "            print(f\"No improvement for {patience} consecutive epochs\")\n",
        "            print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
        "            break\n",
        "\n",
        "    # Estimated time remaining\n",
        "    if epoch < NUM_EPOCHS - 1:\n",
        "        avg_time = sum(epoch_times) / len(epoch_times)\n",
        "        remaining_time = avg_time * (NUM_EPOCHS - epoch - 1)\n",
        "        print(f\"\\nEstimated time remaining: {remaining_time/60:.1f} minutes\")\n",
        "\n",
        "total_training_time = time.time() - training_start_time\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETED!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total training time: {total_training_time/60:.2f} minutes\")\n",
        "print(f\"Epochs trained: {len(train_losses)}\")\n",
        "print(f\"Average time per epoch: {total_training_time/len(train_losses):.2f}s\")\n",
        "\n",
        "print(f\"\\nBest Results:\")\n",
        "print(f\"  Best Val Loss: {best_val_loss:.4f}\")\n",
        "print(f\"  Best Val Perplexity: {math.exp(min(best_val_loss, 10)):.2f}\")\n",
        "print(f\"  Best Epoch: {val_losses.index(min(val_losses)) + 1}\")\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"  Final Train Loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"  Final Val Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "print(f\"\\nModel saved as: best_urdu_transformer.pt\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "9nov_oyR5VHr",
        "outputId": "21a212f6-0af9-43e8-b78a-555c333fa91b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training history plots saved!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 16: Plot Training History\n",
        "# ============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss', marker='o')\n",
        "plt.plot(val_losses, label='Validation Loss', marker='s')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "train_perplexity = [math.exp(loss) for loss in train_losses]\n",
        "val_perplexity = [math.exp(loss) for loss in val_losses]\n",
        "plt.plot(train_perplexity, label='Train Perplexity', marker='o')\n",
        "plt.plot(val_perplexity, label='Validation Perplexity', marker='s')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.title('Training and Validation Perplexity')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Training history plots saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmgog9FJ5o_S",
        "outputId": "d0fbb8d2-169c-4060-9ebe-37b929d513ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "LOADING TRAINED MODEL\n",
            "======================================================================\n",
            "✓ Model loaded successfully!\n",
            "\n",
            "Model Details:\n",
            "  Epoch trained: 35\n",
            "  Best Val Loss: 4.4488\n",
            "  Vocabulary size: 10747\n",
            "  Model parameters: 16,546,555\n",
            "\n",
            "Architecture Verification:\n",
            "  d_model: 384\n",
            "  d_ff: 1536 (should be 1536)\n",
            "  n_heads: 6\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 17: Load Trained Model \n",
        "# ============================================================================\n",
        "print(\"=\"*70)\n",
        "print(\"LOADING TRAINED MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load checkpoint (weights_only=False for custom Vocabulary class)\n",
        "checkpoint = torch.load('best_urdu_transformer.pt', map_location=device, weights_only=False)\n",
        "\n",
        "# Load vocabulary first\n",
        "loaded_vocab = checkpoint['vocab']\n",
        "\n",
        "# Create model with EXACT SAME architecture as training\n",
        "loaded_model = Transformer(\n",
        "    vocab_size=loaded_vocab.n_words,\n",
        "    d_model=checkpoint['hyperparameters']['d_model'],\n",
        "    n_heads=checkpoint['hyperparameters']['n_heads'],\n",
        "    n_encoder_layers=checkpoint['hyperparameters']['n_encoder_layers'],\n",
        "    n_decoder_layers=checkpoint['hyperparameters']['n_decoder_layers'],\n",
        "    d_ff=checkpoint['hyperparameters']['d_model'] * 4,  # ← FIXED: was * 2, now * 4\n",
        "    dropout=checkpoint['hyperparameters']['dropout'],\n",
        "    max_len=checkpoint['hyperparameters']['max_len']\n",
        ").to(device)\n",
        "\n",
        "# Load weights\n",
        "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "loaded_model.eval()\n",
        "\n",
        "print(f\"✓ Model loaded successfully!\")\n",
        "print(f\"\\nModel Details:\")\n",
        "print(f\"  Epoch trained: {checkpoint['epoch'] + 1}\")\n",
        "print(f\"  Best Val Loss: {checkpoint['val_loss']:.4f}\")\n",
        "print(f\"  Vocabulary size: {loaded_vocab.n_words}\")\n",
        "print(f\"  Model parameters: {sum(p.numel() for p in loaded_model.parameters()):,}\")\n",
        "\n",
        "# Verify architecture matches training\n",
        "print(f\"\\nArchitecture Verification:\")\n",
        "print(f\"  d_model: {checkpoint['hyperparameters']['d_model']}\")\n",
        "print(f\"  d_ff: {checkpoint['hyperparameters']['d_model'] * 4} (should be 1536)\")\n",
        "print(f\"  n_heads: {checkpoint['hyperparameters']['n_heads']}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv-dIxjz6pMw",
        "outputId": "0e923104-1d8b-444f-d381-fed91e6fa395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "✓ IMPROVED Greedy Decoding Function Defined\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 18: IMPROVED Greedy Search Inference (WITH DIVERSITY)\n",
        "# ============================================================================\n",
        "def greedy_decode(model, input_text, vocab, max_len=50, temperature=0.8, top_k=10, device='cpu'):\n",
        "    \"\"\"\n",
        "    Generate response using greedy decoding with diversity\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize and encode input\n",
        "    input_tokens = tokenize_urdu(input_text)\n",
        "    input_indices = [vocab.word2idx.get(token, vocab.word2idx['<UNK>']) for token in input_tokens]\n",
        "    input_indices = [vocab.word2idx['<SOS>']] + input_indices + [vocab.word2idx['<EOS>']]\n",
        "\n",
        "    # Pad input\n",
        "    if len(input_indices) < max_len:\n",
        "        input_indices += [vocab.word2idx['<PAD>']] * (max_len - len(input_indices))\n",
        "    else:\n",
        "        input_indices = input_indices[:max_len]\n",
        "\n",
        "    # Convert to tensor\n",
        "    encoder_input = torch.tensor([input_indices]).to(device)\n",
        "\n",
        "    # Start with SOS token\n",
        "    decoder_input = [vocab.word2idx['<SOS>']]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step in range(max_len):\n",
        "            # Prepare decoder input\n",
        "            decoder_indices = decoder_input + [vocab.word2idx['<PAD>']] * (max_len - len(decoder_input))\n",
        "            decoder_tensor = torch.tensor([decoder_indices]).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(encoder_input, decoder_tensor)\n",
        "\n",
        "            # Get logits for current position\n",
        "            logits = output[0, step, :]\n",
        "\n",
        "            # Apply temperature and top-k sampling\n",
        "            if temperature > 0 and top_k > 0:\n",
        "                # Temperature scaling\n",
        "                logits = logits / temperature\n",
        "\n",
        "                # Top-k filtering\n",
        "                top_k_logits, top_k_indices = torch.topk(logits, top_k)\n",
        "\n",
        "                # Sample from top-k\n",
        "                probabilities = torch.softmax(top_k_logits, dim=-1)\n",
        "                next_token_idx = torch.multinomial(probabilities, 1).item()\n",
        "                next_token = top_k_indices[next_token_idx].item()\n",
        "            else:\n",
        "                # Standard greedy (fallback)\n",
        "                next_token = logits.argmax().item()\n",
        "\n",
        "            # Stop if EOS\n",
        "            if next_token == vocab.word2idx['<EOS>']:\n",
        "                break\n",
        "\n",
        "            decoder_input.append(next_token)\n",
        "\n",
        "            # Safety check\n",
        "            if len(decoder_input) >= max_len:\n",
        "                break\n",
        "\n",
        "    # Decode to text\n",
        "    generated_tokens = [vocab.idx2word[idx] for idx in decoder_input[1:]]\n",
        "    generated_text = ' '.join(generated_tokens)\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"✓ IMPROVED Greedy Decoding Function Defined\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPZiUMqE6--y",
        "outputId": "cbe5625e-08f6-4b76-d226-e9de2cb4d043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "✓ IMPROVED Beam Search Decoding Function Defined\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 19: IMPROVED Beam Search Inference (WITH DIVERSITY)\n",
        "# ============================================================================\n",
        "def beam_search_decode(model, input_text, vocab, beam_width=3, max_len=50,\n",
        "                      diversity_penalty=0.5, repetition_penalty=1.2, device='cpu'):\n",
        "    \"\"\"\n",
        "    Generate response using beam search with diversity\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize and encode input\n",
        "    input_tokens = tokenize_urdu(input_text)\n",
        "    input_indices = [vocab.word2idx.get(token, vocab.word2idx['<UNK>']) for token in input_tokens]\n",
        "    input_indices = [vocab.word2idx['<SOS>']] + input_indices + [vocab.word2idx['<EOS>']]\n",
        "\n",
        "    # Pad input\n",
        "    if len(input_indices) < max_len:\n",
        "        input_indices += [vocab.word2idx['<PAD>']] * (max_len - len(input_indices))\n",
        "    else:\n",
        "        input_indices = input_indices[:max_len]\n",
        "\n",
        "    encoder_input = torch.tensor([input_indices]).to(device)\n",
        "\n",
        "    # Initialize beams: (sequence, score, length)\n",
        "    beams = [([vocab.word2idx['<SOS>']], 0.0, 1)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step in range(max_len):\n",
        "            candidates = []\n",
        "\n",
        "            for sequence, score, length in beams:\n",
        "                # If sequence already ended, keep it\n",
        "                if sequence[-1] == vocab.word2idx['<EOS>']:\n",
        "                    candidates.append((sequence, score, length))\n",
        "                    continue\n",
        "\n",
        "                # Prepare decoder input\n",
        "                decoder_indices = sequence + [vocab.word2idx['<PAD>']] * (max_len - len(sequence))\n",
        "                decoder_tensor = torch.tensor([decoder_indices]).to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                output = model(encoder_input, decoder_tensor)\n",
        "\n",
        "                # Get log probs for current position\n",
        "                current_pos = len(sequence) - 1\n",
        "                log_probs = torch.log_softmax(output[0, current_pos, :], dim=-1)\n",
        "                top_k_probs, top_k_indices = torch.topk(log_probs, beam_width * 2)  # Get more candidates\n",
        "\n",
        "                # Create new candidates with penalties\n",
        "                for i in range(len(top_k_indices)):\n",
        "                    next_token = top_k_indices[i].item()\n",
        "                    token_prob = top_k_probs[i].item()\n",
        "\n",
        "                    # Apply repetition penalty\n",
        "                    if repetition_penalty > 1.0 and next_token in sequence:\n",
        "                        token_prob = token_prob / repetition_penalty\n",
        "\n",
        "                    # Apply diversity penalty (simplified)\n",
        "                    diversity_bonus = 0.0\n",
        "                    if step > 0:  # Only after first step\n",
        "                        # Give bonus to tokens that are different from other beams\n",
        "                        other_tokens = set()\n",
        "                        for other_seq, _, _ in beams:\n",
        "                            if len(other_seq) > step:\n",
        "                                other_tokens.add(other_seq[step])\n",
        "                        if next_token not in other_tokens:\n",
        "                            diversity_bonus = diversity_penalty\n",
        "\n",
        "                    new_sequence = sequence + [next_token]\n",
        "                    new_score = score + token_prob + diversity_bonus\n",
        "                    new_length = length + 1\n",
        "\n",
        "                    # Length normalization\n",
        "                    normalized_score = new_score / new_length\n",
        "\n",
        "                    candidates.append((new_sequence, normalized_score, new_length))\n",
        "\n",
        "            # Keep top beam_width candidates\n",
        "            beams = sorted(candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "\n",
        "            # Stop if all beams ended\n",
        "            if all(seq[-1] == vocab.word2idx['<EOS>'] for seq, _, _ in beams):\n",
        "                break\n",
        "\n",
        "            # Safety check\n",
        "            if step >= max_len - 1:\n",
        "                break\n",
        "\n",
        "    # Get best sequence\n",
        "    best_sequence, best_score, best_length = beams[0]\n",
        "    best_sequence = best_sequence[1:]  # Skip SOS\n",
        "\n",
        "    # Remove EOS if present\n",
        "    if best_sequence and best_sequence[-1] == vocab.word2idx['<EOS>']:\n",
        "        best_sequence = best_sequence[:-1]\n",
        "\n",
        "    # Decode to text\n",
        "    generated_tokens = [vocab.idx2word[idx] for idx in best_sequence]\n",
        "    generated_text = ' '.join(generated_tokens)\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"✓ IMPROVED Beam Search Decoding Function Defined\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW4XLxiC7KRp",
        "outputId": "e948a7cc-b14f-4b94-fa63-e3d2bd5dc38c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "✓ Helper Functions Defined\n",
            "======================================================================\n",
            "\n",
            "Available functions:\n",
            "  • chat_with_bot(text, method='greedy'/'beam')\n",
            "  • generate_multiple_responses(text)\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CELL 20: Text Generation Helper Functions\n",
        "# ============================================================================\n",
        "def chat_with_bot(input_text, method='greedy', beam_width=3):\n",
        "    \"\"\"\n",
        "    Easy-to-use function to chat with the model\n",
        "\n",
        "    Args:\n",
        "        input_text: Your Urdu question/prompt\n",
        "        method: 'greedy' or 'beam'\n",
        "        beam_width: Beam width if using beam search\n",
        "\n",
        "    Returns:\n",
        "        response: Generated Urdu response\n",
        "    \"\"\"\n",
        "    if method == 'greedy':\n",
        "        response = greedy_decode(loaded_model, input_text, loaded_vocab, device=device)\n",
        "    elif method == 'beam':\n",
        "        response = beam_search_decode(loaded_model, input_text, loaded_vocab,\n",
        "                                      beam_width=beam_width, device=device)\n",
        "    else:\n",
        "        raise ValueError(\"Method must be 'greedy' or 'beam'\")\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "def generate_multiple_responses(input_text, show_both=True):\n",
        "    \"\"\"\n",
        "    Generate responses using both methods for comparison\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"INPUT:\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"  {input_text}\")\n",
        "    print()\n",
        "\n",
        "    if show_both:\n",
        "        print(\"=\"*70)\n",
        "        print(\"GREEDY DECODING:\")\n",
        "        print(\"=\"*70)\n",
        "        greedy_response = chat_with_bot(input_text, method='greedy')\n",
        "        print(f\"  {greedy_response}\")\n",
        "        print()\n",
        "\n",
        "        print(\"=\"*70)\n",
        "        print(\"BEAM SEARCH (width=3):\")\n",
        "        print(\"=\"*70)\n",
        "        beam_response = chat_with_bot(input_text, method='beam', beam_width=3)\n",
        "        print(f\"  {beam_response}\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        return {'greedy': greedy_response, 'beam': beam_response}\n",
        "    else:\n",
        "        response = chat_with_bot(input_text, method='beam', beam_width=3)\n",
        "        print(\"=\"*70)\n",
        "        print(\"RESPONSE:\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"  {response}\")\n",
        "        print(\"=\"*70)\n",
        "        return response\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"✓ Helper Functions Defined\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nAvailable functions:\")\n",
        "print(\"  • chat_with_bot(text, method='greedy'/'beam')\")\n",
        "print(\"  • generate_multiple_responses(text)\")\n",
        "print(\"=\"*70)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM0obQm97Q4v",
        "outputId": "4780075a-e073-4f15-b636-569bf54cac6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TESTING CHATBOT WITH SAMPLE INPUTS\n",
            "======================================================================\n",
            "\n",
            "Generating responses for sample inputs...\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST 1/5\n",
            "======================================================================\n",
            "======================================================================\n",
            "INPUT:\n",
            "======================================================================\n",
            "  آپ کیسے ہیں؟\n",
            "\n",
            "======================================================================\n",
            "GREEDY DECODING:\n",
            "======================================================================\n",
            "  اب ان کو کیا یہ ظلم نہیں ہی\n",
            "\n",
            "======================================================================\n",
            "BEAM SEARCH (width=3):\n",
            "======================================================================\n",
            "  ان سی کیا گیا۔\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST 2/5\n",
            "======================================================================\n",
            "======================================================================\n",
            "INPUT:\n",
            "======================================================================\n",
            "  آج موسم کیسا ہے؟\n",
            "\n",
            "======================================================================\n",
            "GREEDY DECODING:\n",
            "======================================================================\n",
            "  یہ معاملہ کسی نواز شریف کا مقدمہ لڑنا ہی۔\n",
            "\n",
            "======================================================================\n",
            "BEAM SEARCH (width=3):\n",
            "======================================================================\n",
            "  یہاں ہر ادمی پرند سی محبت کرنا ہونا ۔\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST 3/5\n",
            "======================================================================\n",
            "======================================================================\n",
            "INPUT:\n",
            "======================================================================\n",
            "  کیا آپ مجھے مدد کر سکتے ہیں؟\n",
            "\n",
            "======================================================================\n",
            "GREEDY DECODING:\n",
            "======================================================================\n",
            "  کیا اپ کی ساتھ چل سکتا ہوں؟\n",
            "\n",
            "======================================================================\n",
            "BEAM SEARCH (width=3):\n",
            "======================================================================\n",
            "  مجھی بتایا تھا کہ وہ عبادت کی غرض سی جانا\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST 4/5\n",
            "======================================================================\n",
            "======================================================================\n",
            "INPUT:\n",
            "======================================================================\n",
            "  پاکستان کہاں ہے؟\n",
            "\n",
            "======================================================================\n",
            "GREEDY DECODING:\n",
            "======================================================================\n",
            "  اب بھی وہی قائم ہی۔\n",
            "\n",
            "======================================================================\n",
            "BEAM SEARCH (width=3):\n",
            "======================================================================\n",
            "  یہ تو رونا رہی گا۔\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST 5/5\n",
            "======================================================================\n",
            "======================================================================\n",
            "INPUT:\n",
            "======================================================================\n",
            "  میں کھانا کھانا چاہتا ہوں\n",
            "\n",
            "======================================================================\n",
            "GREEDY DECODING:\n",
            "======================================================================\n",
            "  ہم پرانی رویوں میں بندھی ہوئی ہیں۔\n",
            "\n",
            "======================================================================\n",
            "BEAM SEARCH (width=3):\n",
            "======================================================================\n",
            "  جب ہم زیاں کا اندازہ کرتی ہیں۔\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "✓ INFERENCE TESTING COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "You can now:\n",
            "  1. Use chat_with_bot('your urdu text') to get responses\n",
            "  2. Use generate_multiple_responses('your text') to compare methods\n",
            "  3. Proceed to evaluation metrics (Cells 22-27)\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CELL 21: Test Interactive Generation\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING CHATBOT WITH SAMPLE INPUTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test samples from different categories\n",
        "test_inputs = [\n",
        "    \"آپ کیسے ہیں؟\",  # How are you?\n",
        "    \"آج موسم کیسا ہے؟\",  # How is the weather today?\n",
        "    \"کیا آپ مجھے مدد کر سکتے ہیں؟\",  # Can you help me?\n",
        "    \"پاکستان کہاں ہے؟\",  # Where is Pakistan?\n",
        "    \"میں کھانا کھانا چاہتا ہوں\",  # I want to eat food\n",
        "]\n",
        "\n",
        "print(\"\\nGenerating responses for sample inputs...\\n\")\n",
        "\n",
        "for i, input_text in enumerate(test_inputs, 1):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TEST {i}/5\")\n",
        "    print(f\"{'='*70}\")\n",
        "    generate_multiple_responses(input_text)\n",
        "    print()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ INFERENCE TESTING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nYou can now:\")\n",
        "print(\"  1. Use chat_with_bot('your urdu text') to get responses\")\n",
        "print(\"  2. Use generate_multiple_responses('your text') to compare methods\")\n",
        "print(\"  3. Proceed to evaluation metrics (Cells 22-27)\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfV0SdGE8BCE",
        "outputId": "8fc0c31a-faef-475f-8fe2-6e25e5ac6bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "INSTALLING EVALUATION LIBRARIES\n",
            "======================================================================\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✓ Libraries installed successfully!\n",
            "  • sacrebleu (for BLEU and chrF)\n",
            "  • rouge-score (for ROUGE-L)\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CELL 22: Install Evaluation Libraries\n",
        "# ============================================================================\n",
        "print(\"=\"*70)\n",
        "print(\"INSTALLING EVALUATION LIBRARIES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "!pip install -q sacrebleu rouge-score\n",
        "\n",
        "print(\"✓ Libraries installed successfully!\")\n",
        "print(\"  • sacrebleu (for BLEU and chrF)\")\n",
        "print(\"  • rouge-score (for ROUGE-L)\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiHzq8Xk8LcN",
        "outputId": "bd06d7c6-ecf6-4176-bc77-c3c11f100922"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "GENERATING PREDICTIONS ON TEST SET\n",
            "======================================================================\n",
            "\n",
            "Generating responses for 1956 test samples...\n",
            "This may take a few minutes...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating:  10%|█         | 203/1956 [00:10<01:10, 24.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Sample 200:\n",
            "    Input:      بولی وڈ میں پاکستانی ہدایتکاروں کو کوئی نہیں جانتا...\n",
            "    Reference:  کالی کافی اور سگاروں پہ گزارا کرتے۔...\n",
            "    Prediction: تو یہ کسی نی اب اس کی ساتھ ہاتھ میں سوال کو بھی کہ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating:  21%|██        | 402/1956 [00:18<01:23, 18.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Sample 400:\n",
            "    Input:      اس میں ایک مسئلہ ہے۔...\n",
            "    Reference:  پیچھے سے جا ٹکر...\n",
            "    Prediction: ہمیں محض اسی سمجھنی کی ضرورت ہی...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating:  31%|███       | 603/1956 [00:27<01:05, 20.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Sample 600:\n",
            "    Input:      کی متبادل معیاری اصطلاحات یہی...\n",
            "    Reference:  اب اس تصویر پر لے دے ہو رہی ہے اور متعلقہ ایڈ ا...\n",
            "    Prediction: قوم کی شعوری تربیت کرتی ہی۔...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating:  41%|████      | 802/1956 [00:36<00:54, 21.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Sample 800:\n",
            "    Input:      اخبارات <SENTINEL_0> ترسیل کنٹرول ہو سکتی ہی۔...\n",
            "    Reference:  اخبارات کی ترسیل کنٹرول ہو سکتی ہے۔...\n",
            "    Prediction: یہ اج بالکل مختلف منظر نامی میں تبدیلی ہو سکتی ہی۔...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating:  51%|█████▏    | 1004/1956 [00:46<00:38, 24.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Sample 1000:\n",
            "    Input:      اطراف سے وافر دلائل مو جود ہیں۔...\n",
            "    Reference:  میں نے ایک آری دیکھی جو دیکھ نہ پایا۔...\n",
            "    Prediction: اور بعض مسلمان سمجھتی ہیں...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating:  62%|██████▏   | 1203/1956 [00:55<00:44, 16.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Sample 1200:\n",
            "    Input:      آج ہم ایک عجیب مخمصے میں پھنسے ہیں۔...\n",
            "    Reference:  تو سب ٹھیک ہو جائے گا۔...\n",
            "    Prediction: وہ اپنی بندوں پر پوری طرح حاوی ہی...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating:  72%|███████▏  | 1402/1956 [01:04<00:27, 19.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Sample 1400:\n",
            "    Input:      گر فکرِ زخم کی تو خطاوار ہیں کہ ہم...\n",
            "    Reference:  آفیشل دورہ پر چترال گئے تھے...\n",
            "    Prediction: اس سی کیا حساب برابر ہو جاتا ہی؟...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating:  82%|████████▏ | 1601/1956 [01:13<00:18, 19.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Sample 1600:\n",
            "    Input:      ریاست اسی نظر انداز کری <SENTINEL_0> لیتی ہی۔...\n",
            "    Reference:  ریاست اسے نظر انداز کرے تولاقانونیت جنم لیتی ہے۔...\n",
            "    Prediction: اسی طرح مقبول ترین باب کھلا ہی۔...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating:  92%|█████████▏| 1803/1956 [01:22<00:07, 20.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Sample 1800:\n",
            "    Input:      نعام اس کی طالبعلموں کی امتحان میں زیادہ نمبر حاصل...\n",
            "    Reference:  چترال کی دل کش وادی میں بہتی ندیاں...\n",
            "    Prediction: لیکن یہ تو شروعات ہی۔...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating: 100%|██████████| 1956/1956 [01:29<00:00, 21.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "✓ Generated 1956 predictions!\n",
            "======================================================================\n",
            "\n",
            "Sample predictions:\n",
            "                                               input  \\\n",
            "0                                     جیسے پہلے تھے۔   \n",
            "1  تاکہ ہمارے ماحول کی حسن برقرار رہے اور لوگوں م...   \n",
            "2                     وسطی ایشیا کے علاقوں کو دیکھیں   \n",
            "\n",
            "                                           reference  \\\n",
            "0                                      بہت روتے ہیں۔   \n",
            "1  اسڑیلوی کرکٹ ٹیم کے نائب کپتان ڈیوڈ وارنر دورہ...   \n",
            "2  جب پاکستان کے تمام بکاو چینل پر کرونا وائرس کو...   \n",
            "\n",
            "                        prediction  \n",
            "0   اس کی ائینی کردار کا تقاضا ہی۔  \n",
            "1  اس نی ملک میں ان سی یہ نہیں کی۔  \n",
            "2     وہاں میری ایک دوست وسیم اکرم  \n",
            "\n",
            "======================================================================\n",
            "DIVERSITY CHECK (First 10 predictions):\n",
            "======================================================================\n",
            "Unique predictions in first 10 samples: 10/10\n",
            "✅ Excellent diversity!\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 23: Generate Predictions on Test Set - GREEDY ONLY WITH DIVERSITY\n",
        "# ============================================================================\n",
        "import sacrebleu\n",
        "from rouge_score import rouge_scorer\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GENERATING PREDICTIONS ON TEST SET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create test dataloader (batch_size=1 for easier processing)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "print(f\"\\nGenerating responses for {len(test_dataset)} test samples...\")\n",
        "print(\"This may take a few minutes...\\n\")\n",
        "\n",
        "loaded_model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(test_loader, desc=\"Generating\")):\n",
        "        # Get input and reference\n",
        "        encoder_input = batch['encoder_input'].to(device)\n",
        "        decoder_target = batch['decoder_target'].to(device)\n",
        "\n",
        "        # Get original text\n",
        "        input_text = test_data.iloc[i]['input']\n",
        "        reference_text = test_data.iloc[i]['response']\n",
        "\n",
        "        # USE ONLY GREEDY DECODE WITH DIVERSITY (no beam search)\n",
        "        prediction = greedy_decode(\n",
        "            loaded_model,\n",
        "            input_text,\n",
        "            loaded_vocab,\n",
        "            max_len=50,\n",
        "            temperature=0.9,           # Balanced temperature\n",
        "            top_k=12,                  # Good diversity\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        predictions.append(prediction)\n",
        "        references.append(reference_text)\n",
        "\n",
        "        # Show progress every 200 samples\n",
        "        if (i + 1) % 200 == 0:\n",
        "            print(f\"\\n  Sample {i+1}:\")\n",
        "            print(f\"    Input:      {input_text[:50]}...\")\n",
        "            print(f\"    Reference:  {reference_text[:50]}...\")\n",
        "            print(f\"    Prediction: {prediction[:50]}...\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"✓ Generated {len(predictions)} predictions!\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Save predictions for later analysis\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame({\n",
        "    'input': [test_data.iloc[i]['input'] for i in range(len(predictions))],\n",
        "    'reference': references,\n",
        "    'prediction': predictions\n",
        "})\n",
        "\n",
        "print(\"\\nSample predictions:\")\n",
        "print(results_df.head(3))\n",
        "\n",
        "# Quick diversity check\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"DIVERSITY CHECK (First 10 predictions):\")\n",
        "print(f\"{'='*70}\")\n",
        "unique_predictions = len(set(predictions[:10]))\n",
        "print(f\"Unique predictions in first 10 samples: {unique_predictions}/10\")\n",
        "if unique_predictions >= 8:\n",
        "    print(\"✅ Excellent diversity!\")\n",
        "elif unique_predictions >= 5:\n",
        "    print(\"✅ Good diversity!\")\n",
        "else:\n",
        "    print(\"❌ Low diversity - consider increasing temperature\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqqpWG2jECXp",
        "outputId": "e7a3ab55-fdb9-4142-c50b-36e8f47e9015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CALCULATING BLEU SCORE\n",
            "======================================================================\n",
            "\n",
            "BLEU Scores:\n",
            "  BLEU:    16.52\n",
            "  BLEU-1:  71.43\n",
            "  BLEU-2:  16.67\n",
            "  BLEU-3:  10.00\n",
            "  BLEU-4:  6.25\n",
            "  BP (Brevity Penalty): 1.0000\n",
            "\n",
            "======================================================================\n",
            "BLEU Score Interpretation:\n",
            "  0-10:  Very poor\n",
            "  10-20: Poor\n",
            "  20-30: Acceptable\n",
            "  30-40: Good\n",
            "  40-50: Very Good\n",
            "  50+:   Excellent\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CELL 24: Calculate BLEU Score\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CALCULATING BLEU SCORE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Prepare data for BLEU (sacrebleu expects list of references)\n",
        "bleu_references = [[ref] for ref in references]  # Wrap each reference in a list\n",
        "bleu_predictions = predictions\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu = sacrebleu.corpus_bleu(bleu_predictions, bleu_references)\n",
        "\n",
        "print(f\"\\nBLEU Scores:\")\n",
        "print(f\"  BLEU:    {bleu.score:.2f}\")\n",
        "print(f\"  BLEU-1:  {bleu.precisions[0]:.2f}\")\n",
        "print(f\"  BLEU-2:  {bleu.precisions[1]:.2f}\")\n",
        "print(f\"  BLEU-3:  {bleu.precisions[2]:.2f}\")\n",
        "print(f\"  BLEU-4:  {bleu.precisions[3]:.2f}\")\n",
        "print(f\"  BP (Brevity Penalty): {bleu.bp:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"BLEU Score Interpretation:\")\n",
        "print(\"  0-10:  Very poor\")\n",
        "print(\"  10-20: Poor\")\n",
        "print(\"  20-30: Acceptable\")\n",
        "print(\"  30-40: Good\")\n",
        "print(\"  40-50: Very Good\")\n",
        "print(\"  50+:   Excellent\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgqIzIkTEMTr",
        "outputId": "a93ffd55-5317-403d-d33b-97e428a0a16e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CALCULATING ROUGE-L SCORE\n",
            "======================================================================\n",
            "\n",
            "ROUGE-L Scores:\n",
            "  Average ROUGE-L F1: 0.0000\n",
            "  Min ROUGE-L:        0.0000\n",
            "  Max ROUGE-L:        0.0000\n",
            "\n",
            "  Average Precision:  0.0000\n",
            "  Average Recall:     0.0000\n",
            "\n",
            "======================================================================\n",
            "ROUGE-L Score Interpretation:\n",
            "  0.0-0.2: Poor overlap\n",
            "  0.2-0.4: Fair overlap\n",
            "  0.4-0.6: Good overlap\n",
            "  0.6-0.8: Very good overlap\n",
            "  0.8-1.0: Excellent overlap\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CELL 25: Calculate ROUGE-L Score\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CALCULATING ROUGE-L SCORE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=False)\n",
        "\n",
        "rouge_scores = []\n",
        "for pred, ref in zip(predictions, references):\n",
        "    score = scorer.score(ref, pred)\n",
        "    rouge_scores.append(score['rougeL'].fmeasure)\n",
        "\n",
        "# Calculate average\n",
        "avg_rouge_l = sum(rouge_scores) / len(rouge_scores)\n",
        "\n",
        "print(f\"\\nROUGE-L Scores:\")\n",
        "print(f\"  Average ROUGE-L F1: {avg_rouge_l:.4f}\")\n",
        "print(f\"  Min ROUGE-L:        {min(rouge_scores):.4f}\")\n",
        "print(f\"  Max ROUGE-L:        {max(rouge_scores):.4f}\")\n",
        "\n",
        "# Calculate precision and recall separately\n",
        "rouge_precision = []\n",
        "rouge_recall = []\n",
        "for pred, ref in zip(predictions, references):\n",
        "    score = scorer.score(ref, pred)\n",
        "    rouge_precision.append(score['rougeL'].precision)\n",
        "    rouge_recall.append(score['rougeL'].recall)\n",
        "\n",
        "avg_precision = sum(rouge_precision) / len(rouge_precision)\n",
        "avg_recall = sum(rouge_recall) / len(rouge_recall)\n",
        "\n",
        "print(f\"\\n  Average Precision:  {avg_precision:.4f}\")\n",
        "print(f\"  Average Recall:     {avg_recall:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ROUGE-L Score Interpretation:\")\n",
        "print(\"  0.0-0.2: Poor overlap\")\n",
        "print(\"  0.2-0.4: Fair overlap\")\n",
        "print(\"  0.4-0.6: Good overlap\")\n",
        "print(\"  0.6-0.8: Very good overlap\")\n",
        "print(\"  0.8-1.0: Excellent overlap\")\n",
        "print(f\"{'='*70}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNi4-AIXEUsc",
        "outputId": "1af9b4f8-6b2d-4ab6-c1ec-b69f8b49c593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CALCULATING chrF SCORE\n",
            "======================================================================\n",
            "\n",
            "chrF Scores:\n",
            "  chrF:   26.59\n",
            "  chrF++: 26.59\n",
            "\n",
            "======================================================================\n",
            "chrF Score Interpretation:\n",
            "  0-20:  Very poor character overlap\n",
            "  20-40: Poor character overlap\n",
            "  40-60: Acceptable character overlap\n",
            "  60-80: Good character overlap\n",
            "  80+:   Excellent character overlap\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "CALCULATING PERPLEXITY ON TEST SET\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 62/62 [00:01<00:00, 40.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set Results:\n",
            "  Test Loss:       4.5187\n",
            "  Test Perplexity: 91.72\n",
            "\n",
            "======================================================================\n",
            "Perplexity Interpretation:\n",
            "  Lower is better (indicates model confidence)\n",
            "  < 50:   Excellent\n",
            "  50-100: Good\n",
            "  100-200: Acceptable\n",
            "  > 200:  Poor\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CELL 26: Calculate chrF Score and Perplexity\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CALCULATING chrF SCORE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate chrF score (character-level F-score)\n",
        "chrf = sacrebleu.corpus_chrf(bleu_predictions, bleu_references)\n",
        "\n",
        "print(f\"\\nchrF Scores:\")\n",
        "print(f\"  chrF:   {chrf.score:.2f}\")\n",
        "print(f\"  chrF++: {chrf.score:.2f}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"chrF Score Interpretation:\")\n",
        "print(\"  0-20:  Very poor character overlap\")\n",
        "print(\"  20-40: Poor character overlap\")\n",
        "print(\"  40-60: Acceptable character overlap\")\n",
        "print(\"  60-80: Good character overlap\")\n",
        "print(\"  80+:   Excellent character overlap\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PERPLEXITY ON TEST SET\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CALCULATING PERPLEXITY ON TEST SET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create test dataloader with original batch size\n",
        "test_loader_eval = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Calculate perplexity\n",
        "test_loss = evaluate(loaded_model, test_loader_eval, criterion, device)\n",
        "test_perplexity = math.exp(min(test_loss, 10))  # Cap to prevent overflow\n",
        "\n",
        "print(f\"\\nTest Set Results:\")\n",
        "print(f\"  Test Loss:       {test_loss:.4f}\")\n",
        "print(f\"  Test Perplexity: {test_perplexity:.2f}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"Perplexity Interpretation:\")\n",
        "print(\"  Lower is better (indicates model confidence)\")\n",
        "print(\"  < 50:   Excellent\")\n",
        "print(\"  50-100: Good\")\n",
        "print(\"  100-200: Acceptable\")\n",
        "print(\"  > 200:  Poor\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsjJvJQDEdGL",
        "outputId": "7a1dd02a-fda3-46ca-a85d-4c4faf20edfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "QUALITATIVE EVALUATION: MODEL vs GROUND TRUTH\n",
            "======================================================================\n",
            "\n",
            "Showing 30 examples:\n",
            "\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 1/30\n",
            "======================================================================\n",
            "Input:\n",
            "  جیسے پہلے تھے۔\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  بہت روتے ہیں۔\n",
            "\n",
            "Model Prediction:\n",
            "  اس کی ائینی کردار کا تقاضا ہی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 2/30\n",
            "======================================================================\n",
            "Input:\n",
            "  تاکہ ہمارے ماحول کی حسن برقرار رہے اور لوگوں میں شعور اجاگر کیا جائے کہ جانوروں کو مار نا صرف گناہ ہی نہیں\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  اسڑیلوی کرکٹ ٹیم کے نائب کپتان ڈیوڈ وارنر دورہ بنگلہ دیش سے باہر\n",
            "\n",
            "Model Prediction:\n",
            "  اس نی ملک میں ان سی یہ نہیں کی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 3/30\n",
            "======================================================================\n",
            "Input:\n",
            "  وسطی ایشیا کے علاقوں کو دیکھیں\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  جب پاکستان کے تمام بکاو چینل پر کرونا وائرس کو لیکر جھوٹ اور خوف و ہراس پھیلایا جارہا تھا\n",
            "\n",
            "Model Prediction:\n",
            "  وہاں میری ایک دوست وسیم اکرم\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 4/30\n",
            "======================================================================\n",
            "Input:\n",
            "  اس کا ہمیں نہیں پتہ۔\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  پہاڑی لوگوں کے بارے میں اکثر سنا تھا\n",
            "\n",
            "Model Prediction:\n",
            "  ہمیں محض اسی سمجھنی اور دوسری طرف قرار دیتی ہیں\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 5/30\n",
            "======================================================================\n",
            "Input:\n",
            "  حسب معمول بنائے بغیر چھٹائی کریں\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  پیسہ تجوریوں میں ہے۔\n",
            "\n",
            "Model Prediction:\n",
            "  تو پھر کپتان کوئی بھی ہو ، مثبت نتائج کی فراوانی نہیں رک سکی گی\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 6/30\n",
            "======================================================================\n",
            "Input:\n",
            "  جاپانی جواب دیتے ہیں کہ رعایتیں دینے کے لیے پہلا مرحلہ بہت جلدی تھا\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  درِ اظہارِ مروت سے تُم آؤ۔۔جاؤ\n",
            "\n",
            "Model Prediction:\n",
            "  یہی معاملہ امت مسلمہ کا بھی ہی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 7/30\n",
            "======================================================================\n",
            "Input:\n",
            "  امیر محترم نے فیصلہ کیا کہ پہلے ایک آملیٹ چاٹ مصالحہ ڈال کر بنایا جائے اور اسے چیک کیا جائے\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  ہونٹوں کی ہلکی سی جنبش سے ٹوٹ جاتی ہے\n",
            "\n",
            "Model Prediction:\n",
            "  ان سی ایک ہی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    4.58\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 8/30\n",
            "======================================================================\n",
            "Input:\n",
            "  ان میں بے شمار فرقے ہیں اور بہت سے لوگ لبرل ہیں۔ دپیکا سب سے مہنگی اداکارہ\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  ایسے لوگ بھی ہر جگہ پسند کیے جاتے ہیں\n",
            "\n",
            "Model Prediction:\n",
            "  یہ سب باتیں میری علم میں ہیں۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 9/30\n",
            "======================================================================\n",
            "Input:\n",
            "  عنقریب یہ وبا انشاءاللہ پاکستان سے ختم ہورہی ہے\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  دفاع ہماری ضرورت تھی۔\n",
            "\n",
            "Model Prediction:\n",
            "  اگر یہ ہو جائی تو فلاں شخص کافر ہی\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 10/30\n",
            "======================================================================\n",
            "Input:\n",
            "  سخت مشکل صورت حال میں بھی مطمئن رہتا ہوں\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  ریاست یہ سب کام اپنے وسائل کے تحت ہی کر سکتی ہے۔\n",
            "\n",
            "Model Prediction:\n",
            "  یہ مشکل وقت بھی گزر گئی ہی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    3.21\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 11/30\n",
            "======================================================================\n",
            "Input:\n",
            "  دنیا کا ایک بڑا نہری نظام بھی پاکستان کے پاس موجود ہے\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  مولانا امین احسن اصلاحی اس کی وضاحت کرتے ہوئے لکھتے ہیں\n",
            "\n",
            "Model Prediction:\n",
            "  نہ کوئی نشان حیدر یا کوئی ستائش کا کوئی موثر طریقہ ہی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 12/30\n",
            "======================================================================\n",
            "Input:\n",
            "  ہم میں وہ خصوصیات کیسے پیداہونگی؟\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  دیانتدار قیادت کو مسترد کرنے پر عوام کو کوستے ہیں\n",
            "\n",
            "Model Prediction:\n",
            "  یہ تو رونا ہی کہ وہ اپنی ذہنی سانچی ہی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 13/30\n",
            "======================================================================\n",
            "Input:\n",
            "  اس سے پہلے لیکن انہیں سیاست دان سے لیڈر بننا ہے۔\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  معمول کبھی ‘‘۔\n",
            "\n",
            "Model Prediction:\n",
            "  پاکستان کرکٹ ٹیم جنوبی افریقہ اور سری لنکا کی درمیان پوسٹ افریدی\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 14/30\n",
            "======================================================================\n",
            "Input:\n",
            "  بدو لوگ ریگستان میں رہتے ہیں۔\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  امیں یکدم گھبرا کر برے خواب سے چونکا\n",
            "\n",
            "Model Prediction:\n",
            "  ہم پرانی رویوں میں بندھی ہوئی ہیں۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 15/30\n",
            "======================================================================\n",
            "Input:\n",
            "  چاند اپنے جوبن پر تھا اور نورانی کرنیں ہر سو پھیل کر منظر کی لطافت کو مزید نکھار رہی تھیں\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  اب بہتری کی امید ہے۔\n",
            "\n",
            "Model Prediction:\n",
            "  ہماری پاکستانی قوم چاہتی کیا ہی؟\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 16/30\n",
            "======================================================================\n",
            "Input:\n",
            "  ماتحت عدالتیں کس خوف کا شکار تھیں؟\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  کسی سے اس کی آمدنی کے بارے میں سوال نہی کرنا چاہیے\n",
            "\n",
            "Model Prediction:\n",
            "  تو مسلمان ابھی عرب کی حدود سی باہر نہیں نکلی تھی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    3.42\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 17/30\n",
            "======================================================================\n",
            "Input:\n",
            "  فتنے کا پہلا ہدف امن ہو تا ہے۔\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  اورہم کہاں جارہے ہیں؟\n",
            "\n",
            "Model Prediction:\n",
            "  یہ بھی ایک حل ہی ہی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 18/30\n",
            "======================================================================\n",
            "Input:\n",
            "  وہ <SENTINEL_0> چل رہی ہی۔\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  وہ بیساکھیوں کے سہارے چل رہی ہے۔\n",
            "\n",
            "Model Prediction:\n",
            "  وہ اگر ماضی تھا۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    7.55\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 19/30\n",
            "======================================================================\n",
            "Input:\n",
            "  چھ انڈے الگ کئے ۔ کیا دور دیکھنے والی ان کی نظر تھی۔\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  سب نے نیک خواہشات کے ساتھ ہمیں الوداع کیا\n",
            "\n",
            "Model Prediction:\n",
            "  کوئی تعصب نظر نہیں اتا\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 20/30\n",
            "======================================================================\n",
            "Input:\n",
            "  بچوں کے انٹرنیٹ کے استعمال کا جائزہ لیا گیا\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  مبشر صدیق صاحب آپ کو دعائیں ہیں آپ کے والد محترم کی\n",
            "\n",
            "Model Prediction:\n",
            "  وہ فوج جس کا کام سرحدوں کی حفاظت ہی اس نی ملک میں بڑی بڑی بڑی بڑی بڑی بڑی بڑی کاروبار شروع کر رکھی ہیں\n",
            "\n",
            "Scores:\n",
            "  BLEU:    1.79\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 21/30\n",
            "======================================================================\n",
            "Input:\n",
            "  بزرگوں کو زندہ لاشیں سمجھتے ہیں\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  آج اس ملک میں آئین، نظام اور جمہوریت مو جود ہیں۔\n",
            "\n",
            "Model Prediction:\n",
            "  یہ بھی صریحا مذاق ہی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 22/30\n",
            "======================================================================\n",
            "Input:\n",
            "  انہیں فلاپ <SENTINEL_0> کہا جاسکتا۔\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  انہیں فلاپ نہیں کہا جاسکتا۔\n",
            "\n",
            "Model Prediction:\n",
            "  انہیں بتایا جائی تو انہیں سیاست کی معیشت کا فیصلہ کیا کہا جائی گا؟\n",
            "\n",
            "Scores:\n",
            "  BLEU:    3.38\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 23/30\n",
            "======================================================================\n",
            "Input:\n",
            "  کے نتائج بھی وسعت اختیار کرجاتے ہیں\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  دوسرے روز کروڑ\n",
            "\n",
            "Model Prediction:\n",
            "  جس سی کدورت میں اور بھی اضافہ ہوتا ہی\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 24/30\n",
            "======================================================================\n",
            "Input:\n",
            "  تو اس کے ساتھ ہم خود بھی\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  پاکستان میں ہمارا کل اسلام نماز جمعہ اور مولبی کی تقریر کے علاوہ کچھ نہ تھا\n",
            "\n",
            "Model Prediction:\n",
            "  یہ تو ہماری ریاست ہماری ہاں ہی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 25/30\n",
            "======================================================================\n",
            "Input:\n",
            "  ان نے کہا کہہ بیٹنگ ئن اپ کو سر مرتبہ کر کی ضرورت ہے\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  آمریتوں نے اگر فکری یکسوئی پیدا کی تو جمہوری ادوار نے\n",
            "\n",
            "Model Prediction:\n",
            "  اپ نی امتحان کی تیاری کر لی ہی\n",
            "\n",
            "Scores:\n",
            "  BLEU:    3.80\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 26/30\n",
            "======================================================================\n",
            "Input:\n",
            "  کراچی استنبول نہ بن پایا\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  اس نے پوچھا\n",
            "\n",
            "Model Prediction:\n",
            "  میں طوفان میں مسلسل نفرت کا سبب بن چکی ہی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 27/30\n",
            "======================================================================\n",
            "Input:\n",
            "  انکے پاس پاکستانی پاسپورٹ ہوتا ہے\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  وہ اگر ٹھیک تھی۔\n",
            "\n",
            "Model Prediction:\n",
            "  اور یہ کرنا ہونا شروع کرنا ہر جگہ کسی قسم کا بھی نہیں ۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 28/30\n",
            "======================================================================\n",
            "Input:\n",
            "  ہم نے ایسا کوئی بیان نہیں دیا\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  جب تک میں مکمل راکھ نہیں ہو جاتا\n",
            "\n",
            "Model Prediction:\n",
            "  یہ تو ہماری اپنی بربادی کا میدان ہی۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 29/30\n",
            "======================================================================\n",
            "Input:\n",
            "  اسٹریلیا کی ٹیسٹ رینکنگ میں دو درجہ تنزلی\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  ٹرمپ انتظامیہ کا بہتریں فیصلہ\n",
            "\n",
            "Model Prediction:\n",
            "  اور پھر ممکن ہی کہ پاکستان بھی ہو\n",
            "\n",
            "Scores:\n",
            "  BLEU:    0.00\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE 30/30\n",
            "======================================================================\n",
            "Input:\n",
            "  سنیل گواسکر کمنٹری مائیک پہ تھے۔\n",
            "\n",
            "Ground Truth (Reference):\n",
            "  پاکستان کے مطالبے کی یہی بنیاد تھی۔\n",
            "\n",
            "Model Prediction:\n",
            "  تو پھر کپتان کوئی بھی ہو ، مثبت نتائج کی فراوانی نہیں رک سکی گی ۔\n",
            "\n",
            "Scores:\n",
            "  BLEU:    2.45\n",
            "  ROUGE-L: 0.0000\n",
            "\n",
            "======================================================================\n",
            "EVALUATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Automatic Metrics (Test Set - 1956 samples):\n",
            "  BLEU Score:      16.52\n",
            "  ROUGE-L F1:      0.0000\n",
            "  chrF Score:      26.59\n",
            "  Test Perplexity: 91.72\n",
            "  Test Loss:       4.5187\n",
            "\n",
            "======================================================================\n",
            "✓ EVALUATION COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "✓ Results saved to 'evaluation_results.csv'\n",
            "\n",
            "Metrics Summary:\n",
            "  BLEU: 16.51582159006904\n",
            "  ROUGE-L: 0.0\n",
            "  chrF: 26.587009294478165\n",
            "  Test_Perplexity: 91.71650721148407\n",
            "  Test_Loss: 4.518702376273371\n",
            "  Total_Test_Samples: 1956\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CELL 27: Qualitative Evaluation Examples\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"QUALITATIVE EVALUATION: MODEL vs GROUND TRUTH\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Select diverse examples (first 10, middle 10, last 10)\n",
        "sample_indices = list(range(10)) + list(range(len(predictions)//2 - 5, len(predictions)//2 + 5)) + list(range(len(predictions) - 10, len(predictions)))\n",
        "\n",
        "print(f\"\\nShowing {len(sample_indices)} examples:\\n\")\n",
        "\n",
        "for i, idx in enumerate(sample_indices, 1):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"EXAMPLE {i}/{len(sample_indices)}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Input:\")\n",
        "    print(f\"  {results_df.iloc[idx]['input']}\")\n",
        "    print(f\"\\nGround Truth (Reference):\")\n",
        "    print(f\"  {results_df.iloc[idx]['reference']}\")\n",
        "    print(f\"\\nModel Prediction:\")\n",
        "    print(f\"  {results_df.iloc[idx]['prediction']}\")\n",
        "\n",
        "    # Calculate individual scores for this example\n",
        "    bleu_single = sacrebleu.sentence_bleu(\n",
        "        results_df.iloc[idx]['prediction'],\n",
        "        [results_df.iloc[idx]['reference']]\n",
        "    )\n",
        "    rouge_single = scorer.score(\n",
        "        results_df.iloc[idx]['reference'],\n",
        "        results_df.iloc[idx]['prediction']\n",
        "    )\n",
        "\n",
        "    print(f\"\\nScores:\")\n",
        "    print(f\"  BLEU:    {bleu_single.score:.2f}\")\n",
        "    print(f\"  ROUGE-L: {rouge_single['rougeL'].fmeasure:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SUMMARY OF ALL METRICS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nAutomatic Metrics (Test Set - {len(predictions)} samples):\")\n",
        "print(f\"  BLEU Score:      {bleu.score:.2f}\")\n",
        "print(f\"  ROUGE-L F1:      {avg_rouge_l:.4f}\")\n",
        "print(f\"  chrF Score:      {chrf.score:.2f}\")\n",
        "print(f\"  Test Perplexity: {test_perplexity:.2f}\")\n",
        "print(f\"  Test Loss:       {test_loss:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"✓ EVALUATION COMPLETE!\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv('evaluation_results.csv', index=False)\n",
        "print(\"\\n✓ Results saved to 'evaluation_results.csv'\")\n",
        "\n",
        "# Create metrics summary\n",
        "metrics_summary = {\n",
        "    'BLEU': bleu.score,\n",
        "    'ROUGE-L': avg_rouge_l,\n",
        "    'chrF': chrf.score,\n",
        "    'Test_Perplexity': test_perplexity,\n",
        "    'Test_Loss': test_loss,\n",
        "    'Total_Test_Samples': len(predictions)\n",
        "}\n",
        "\n",
        "print(\"\\nMetrics Summary:\")\n",
        "for metric, value in metrics_summary.items():\n",
        "    print(f\"  {metric}: {value}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
